{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvNKy8wnIWnC"
   },
   "source": [
    "## Binary Classification - Titanic: Machine Learning from Disaster\n",
    "\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "- 유명한 자료인 타이타닉 데이터 셋으로 생존과 사망에 대한 분류 문제를 풀어보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_E7j0LNIWnL"
   },
   "source": [
    "![대체 텍스트](figures/binary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:34:29.202719Z",
     "start_time": "2018-10-28T07:34:29.192102Z"
    },
    "id": "agnpS74dIWnN",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c442900450>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "random.seed(1215)\n",
    "torch.manual_seed(1215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T06:53:30.685976Z",
     "start_time": "2018-10-28T06:53:25.255348Z"
    },
    "id": "u7zoHxKMIWnR"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PNAJqoBIWnS"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:19.716052Z",
     "start_time": "2018-10-28T07:48:19.695224Z"
    },
    "id": "cKCmYPNKIWnT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv(\"./data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"./data/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:20.005530Z",
     "start_time": "2018-10-28T07:48:19.985459Z"
    },
    "id": "mrFf4fedIWnU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "r_q5oZyMIWnW"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>898</td>\n",
       "      <td>3</td>\n",
       "      <td>Connolly, Miss. Kate</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330972</td>\n",
       "      <td>7.6292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>899</td>\n",
       "      <td>2</td>\n",
       "      <td>Caldwell, Mr. Albert Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>248738</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>Abrahim, Mrs. Joseph (Sophie Halaut Easu)</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2657</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>901</td>\n",
       "      <td>3</td>\n",
       "      <td>Davies, Mr. John Samuel</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A/4 48871</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "5          897       3                    Svensson, Mr. Johan Cervin    male   \n",
       "6          898       3                          Connolly, Miss. Kate  female   \n",
       "7          899       2                  Caldwell, Mr. Albert Francis    male   \n",
       "8          900       3     Abrahim, Mrs. Joseph (Sophie Halaut Easu)  female   \n",
       "9          901       3                       Davies, Mr. John Samuel    male   \n",
       "\n",
       "    Age  SibSp  Parch     Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0     330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0     363272   7.0000   NaN        S  \n",
       "2  62.0      0      0     240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0     315154   8.6625   NaN        S  \n",
       "4  22.0      1      1    3101298  12.2875   NaN        S  \n",
       "5  14.0      0      0       7538   9.2250   NaN        S  \n",
       "6  30.0      0      0     330972   7.6292   NaN        Q  \n",
       "7  26.0      1      1     248738  29.0000   NaN        S  \n",
       "8  18.0      0      0       2657   7.2292   NaN        C  \n",
       "9  21.0      2      0  A/4 48871  24.1500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYihLkpKIWnX"
   },
   "source": [
    "# Preprocessing\n",
    "- Pclass, Sex, Age, SibSp, Parch, Fare 총 6개의 feature를 사용하겠습니다.\n",
    "- 별도의 feature engineering은 하지 않겠습니다.\n",
    "- kaggle data이기 때문에 test_data의 \"Survived\" 열은 없습니다.\n",
    "- 우리가 예측한 결과를 csv 파일로 제출하는 형태입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6Vc2-lyIWnY"
   },
   "source": [
    "### categorical variable 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7an9HpYhIWnZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1    female\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "5      male\n",
       "6      male\n",
       "7      male\n",
       "8    female\n",
       "9    female\n",
       "Name: Sex, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CNufUnrUIWnZ"
   },
   "outputs": [],
   "source": [
    "train_data[\"Sex\"] = train_data[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "test_data[\"Sex\"] = test_data[\"Sex\"].map({\"male\": 1, \"female\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JPv-O0k1IWna"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1\n",
       "8    0\n",
       "9    0\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"Sex\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5vPQ8CTIWnb"
   },
   "source": [
    "### 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:21.754377Z",
     "start_time": "2018-10-28T07:48:21.739961Z"
    },
    "id": "TQZS1Y07IWnb"
   },
   "outputs": [],
   "source": [
    "data_X = train_data[[\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]]\n",
    "data_y = train_data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1T29NlfMIWnc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ZQM82nxWIWnc"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(data_X, data_y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1t6EyPQKIWnd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 623.6999999999999)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(data_X)*.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "__8HHWx_IWnd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 267.3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_X), len(data_X)*.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMbyXoCwIWnd"
   },
   "source": [
    "### null 값 확인 (결측값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:22.020698Z",
     "start_time": "2018-10-28T07:48:22.006813Z"
    },
    "id": "wkDUFZzeIWne"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null in train_X: Pclass      0\n",
      "Sex         0\n",
      "Age       128\n",
      "SibSp       0\n",
      "Parch       0\n",
      "Fare        0\n",
      "dtype: int64\n",
      "\n",
      " Number of null in test_X: Pclass     0\n",
      "Sex        0\n",
      "Age       49\n",
      "SibSp      0\n",
      "Parch      0\n",
      "Fare       0\n",
      "dtype: int64\n",
      "\n",
      " Number of nullin train y: 0\n",
      "\n",
      " Number of nullin train y: 0\n",
      "\n",
      " 29.86937373737374\n"
     ]
    }
   ],
   "source": [
    "print('Number of null in train_X:', train_X.isnull().sum())\n",
    "print(\"\\n\",'Number of null in test_X:', test_X.isnull().sum())\n",
    "print(\"\\n\",'Number of nullin train y:', train_y.isnull().sum())\n",
    "print(\"\\n\",'Number of nullin train y:', test_y.isnull().sum())\n",
    "\n",
    "print(\"\\n\",np.mean(train_X[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiPNWr54IWnf"
   },
   "source": [
    "- 간단하게 age와 fare의 na 값은 평균으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:23.836865Z",
     "start_time": "2018-10-28T07:48:23.823969Z"
    },
    "id": "tHBvPlH-IWnf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_X.loc[:,\"Age\"] = train_X.loc[:,\"Age\"].replace(np.nan,30)\n",
    "test_X.loc[:,\"Age\"] = test_X.loc[:,\"Age\"].replace(np.nan,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:24.418285Z",
     "start_time": "2018-10-28T07:48:24.406782Z"
    },
    "id": "SVlMFybQIWng"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null: Pclass    0\n",
      "Sex       0\n",
      "Age       0\n",
      "SibSp     0\n",
      "Parch     0\n",
      "Fare      0\n",
      "dtype: int64\n",
      "\n",
      " Number of null: Pclass    0\n",
      "Sex       0\n",
      "Age       0\n",
      "SibSp     0\n",
      "Parch     0\n",
      "Fare      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of null:', train_X.isnull().sum())\n",
    "print(\"\\n\",'Number of null:', test_X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:26.498112Z",
     "start_time": "2018-10-28T07:48:26.492656Z"
    },
    "id": "gY--K_7NIWng"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553    1\n",
       "256    1\n",
       "509    1\n",
       "369    1\n",
       "542    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:27.198668Z",
     "start_time": "2018-10-28T07:48:27.192577Z"
    },
    "id": "V4hSGO6JIWnh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 268, 623, 268)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(test_X), len(train_y), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YyBT2WpIWnh"
   },
   "source": [
    "# Train model (PyTorch)\n",
    "1. dataset, dataloader 정의\n",
    "2. 모델 정의\n",
    "3. 모델 학습 \n",
    "4. 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ogKQzIswIWnh"
   },
   "source": [
    "- train, test dataset을 출력할 수 있는 class를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:30.938583Z",
     "start_time": "2018-10-28T07:48:30.931143Z"
    },
    "id": "JU8tNqFHIWni"
   },
   "outputs": [],
   "source": [
    "class simple_dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "        \n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ho6fpa9NIWni"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:32.125111Z",
     "start_time": "2018-10-28T07:48:32.117187Z"
    },
    "id": "ute7KeA2IWnj"
   },
   "outputs": [],
   "source": [
    "# 정규화합니다\n",
    "scaler = StandardScaler()\n",
    "train_data = simple_dataset(torch.FloatTensor(scaler.fit_transform(train_X.to_numpy())), torch.LongTensor(train_y.to_numpy()))\n",
    "test_data = simple_dataset(torch.FloatTensor(scaler.fit_transform(test_X.to_numpy())), torch.LongTensor(test_y.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "twkMiNWqIWnj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623, 268)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T07:48:51.854783Z",
     "start_time": "2018-10-28T07:48:51.849359Z"
    },
    "id": "zczxV0qXIWnj"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.8194,  0.7441, -0.6200, -0.4803, -0.4640, -0.4894]), tensor(1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "-A9dtRJHIWnk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.8194,  0.7441, -0.6200, -0.4803, -0.4640, -0.4894]), tensor(1))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEkoBp4MIWnk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhyjBTm0IWnl"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T08:24:00.698892Z",
     "start_time": "2018-10-28T08:24:00.685532Z"
    },
    "id": "ulVgLBTmIWnl"
   },
   "outputs": [],
   "source": [
    "class Binary_Classification(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Binary_Classification, self).__init__()\n",
    "        \n",
    "        self.Layer_1 = nn.Linear(num_features, 30)\n",
    "        \n",
    "        \n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################\n",
    "        \n",
    "        self.Layer_2 = nn.Linear(30, 15)\n",
    "        self.Layer_3 = nn.Linear(15, 8)\n",
    "        self.Layer_out = nn.Linear(8, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        x = self.Layer_1(inputs)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################\n",
    "        x = self.Layer_2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Layer_3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.Layer_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VJiDT-aIWnl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBPceNy8IWnm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_APaY49IWnm"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "18Nsx8XHIWnm"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3000\n",
    "BATCH_SIZE = 891\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Binary_Classification(num_features=6, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo4sqcq2IWnm"
   },
   "source": [
    "### 데이터 사이즈 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "68y7M5JSIWnn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([623, 6]) torch.Size([623])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        print(X_batch.size(), y_batch.size())\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T08:26:29.145512Z",
     "start_time": "2018-10-28T08:24:02.302520Z"
    },
    "id": "oYWDKFQTIWnn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/3000] Step [1/1] Loss: [0.6896] Train ACC [40.61%]\n",
      "Epoch [60/3000] Step [1/1] Loss: [0.6005] Train ACC [80.26%]\n",
      "Epoch [90/3000] Step [1/1] Loss: [0.4702] Train ACC [82.02%]\n",
      "Epoch [120/3000] Step [1/1] Loss: [0.4151] Train ACC [82.50%]\n",
      "Epoch [150/3000] Step [1/1] Loss: [0.4012] Train ACC [82.99%]\n",
      "Epoch [180/3000] Step [1/1] Loss: [0.3930] Train ACC [83.31%]\n",
      "Epoch [210/3000] Step [1/1] Loss: [0.3861] Train ACC [83.15%]\n",
      "Epoch [240/3000] Step [1/1] Loss: [0.3799] Train ACC [84.27%]\n",
      "Epoch [270/3000] Step [1/1] Loss: [0.3744] Train ACC [84.75%]\n",
      "Epoch [300/3000] Step [1/1] Loss: [0.3691] Train ACC [84.59%]\n",
      "Epoch [330/3000] Step [1/1] Loss: [0.3643] Train ACC [85.07%]\n",
      "Epoch [360/3000] Step [1/1] Loss: [0.3594] Train ACC [85.71%]\n",
      "Epoch [390/3000] Step [1/1] Loss: [0.3551] Train ACC [85.87%]\n",
      "Epoch [420/3000] Step [1/1] Loss: [0.3507] Train ACC [85.55%]\n",
      "Epoch [450/3000] Step [1/1] Loss: [0.3457] Train ACC [85.71%]\n",
      "Epoch [480/3000] Step [1/1] Loss: [0.3408] Train ACC [86.52%]\n",
      "Epoch [510/3000] Step [1/1] Loss: [0.3355] Train ACC [86.68%]\n",
      "Epoch [540/3000] Step [1/1] Loss: [0.3302] Train ACC [86.68%]\n",
      "Epoch [570/3000] Step [1/1] Loss: [0.3248] Train ACC [86.68%]\n",
      "Epoch [600/3000] Step [1/1] Loss: [0.3190] Train ACC [87.00%]\n",
      "Epoch [630/3000] Step [1/1] Loss: [0.3131] Train ACC [87.80%]\n",
      "Epoch [660/3000] Step [1/1] Loss: [0.3067] Train ACC [87.64%]\n",
      "Epoch [690/3000] Step [1/1] Loss: [0.3006] Train ACC [88.28%]\n",
      "Epoch [720/3000] Step [1/1] Loss: [0.2947] Train ACC [88.60%]\n",
      "Epoch [750/3000] Step [1/1] Loss: [0.2880] Train ACC [89.25%]\n",
      "Epoch [780/3000] Step [1/1] Loss: [0.2821] Train ACC [89.57%]\n",
      "Epoch [810/3000] Step [1/1] Loss: [0.2760] Train ACC [89.57%]\n",
      "Epoch [840/3000] Step [1/1] Loss: [0.2702] Train ACC [89.57%]\n",
      "Epoch [870/3000] Step [1/1] Loss: [0.2653] Train ACC [89.41%]\n",
      "Epoch [900/3000] Step [1/1] Loss: [0.2608] Train ACC [89.41%]\n",
      "Epoch [930/3000] Step [1/1] Loss: [0.2565] Train ACC [89.41%]\n",
      "Epoch [960/3000] Step [1/1] Loss: [0.2524] Train ACC [89.41%]\n",
      "Epoch [990/3000] Step [1/1] Loss: [0.2485] Train ACC [89.89%]\n",
      "Epoch [1020/3000] Step [1/1] Loss: [0.2446] Train ACC [89.89%]\n",
      "Epoch [1050/3000] Step [1/1] Loss: [0.2409] Train ACC [90.53%]\n",
      "Epoch [1080/3000] Step [1/1] Loss: [0.2373] Train ACC [90.53%]\n",
      "Epoch [1110/3000] Step [1/1] Loss: [0.2334] Train ACC [90.69%]\n",
      "Epoch [1140/3000] Step [1/1] Loss: [0.2298] Train ACC [90.85%]\n",
      "Epoch [1170/3000] Step [1/1] Loss: [0.2262] Train ACC [90.85%]\n",
      "Epoch [1200/3000] Step [1/1] Loss: [0.2231] Train ACC [91.17%]\n",
      "Epoch [1230/3000] Step [1/1] Loss: [0.2203] Train ACC [91.01%]\n",
      "Epoch [1260/3000] Step [1/1] Loss: [0.2180] Train ACC [91.17%]\n",
      "Epoch [1290/3000] Step [1/1] Loss: [0.2155] Train ACC [91.01%]\n",
      "Epoch [1320/3000] Step [1/1] Loss: [0.2133] Train ACC [90.85%]\n",
      "Epoch [1350/3000] Step [1/1] Loss: [0.2115] Train ACC [91.17%]\n",
      "Epoch [1380/3000] Step [1/1] Loss: [0.2098] Train ACC [91.33%]\n",
      "Epoch [1410/3000] Step [1/1] Loss: [0.2085] Train ACC [91.65%]\n",
      "Epoch [1440/3000] Step [1/1] Loss: [0.2068] Train ACC [91.33%]\n",
      "Epoch [1470/3000] Step [1/1] Loss: [0.2051] Train ACC [91.65%]\n",
      "Epoch [1500/3000] Step [1/1] Loss: [0.2037] Train ACC [91.65%]\n",
      "Epoch [1530/3000] Step [1/1] Loss: [0.2025] Train ACC [91.65%]\n",
      "Epoch [1560/3000] Step [1/1] Loss: [0.2013] Train ACC [91.81%]\n",
      "Epoch [1590/3000] Step [1/1] Loss: [0.2003] Train ACC [91.81%]\n",
      "Epoch [1620/3000] Step [1/1] Loss: [0.1992] Train ACC [91.97%]\n",
      "Epoch [1650/3000] Step [1/1] Loss: [0.1981] Train ACC [91.81%]\n",
      "Epoch [1680/3000] Step [1/1] Loss: [0.1970] Train ACC [91.81%]\n",
      "Epoch [1710/3000] Step [1/1] Loss: [0.1962] Train ACC [92.30%]\n",
      "Epoch [1740/3000] Step [1/1] Loss: [0.1940] Train ACC [92.30%]\n",
      "Epoch [1770/3000] Step [1/1] Loss: [0.1930] Train ACC [92.13%]\n",
      "Epoch [1800/3000] Step [1/1] Loss: [0.1918] Train ACC [92.13%]\n",
      "Epoch [1830/3000] Step [1/1] Loss: [0.1914] Train ACC [91.97%]\n",
      "Epoch [1860/3000] Step [1/1] Loss: [0.1900] Train ACC [92.13%]\n",
      "Epoch [1890/3000] Step [1/1] Loss: [0.1891] Train ACC [92.13%]\n",
      "Epoch [1920/3000] Step [1/1] Loss: [0.1883] Train ACC [92.30%]\n",
      "Epoch [1950/3000] Step [1/1] Loss: [0.1877] Train ACC [92.13%]\n",
      "Epoch [1980/3000] Step [1/1] Loss: [0.1870] Train ACC [92.13%]\n",
      "Epoch [2010/3000] Step [1/1] Loss: [0.1863] Train ACC [92.13%]\n",
      "Epoch [2040/3000] Step [1/1] Loss: [0.1857] Train ACC [92.13%]\n",
      "Epoch [2070/3000] Step [1/1] Loss: [0.1853] Train ACC [92.13%]\n",
      "Epoch [2100/3000] Step [1/1] Loss: [0.1848] Train ACC [92.13%]\n",
      "Epoch [2130/3000] Step [1/1] Loss: [0.1842] Train ACC [92.13%]\n",
      "Epoch [2160/3000] Step [1/1] Loss: [0.1837] Train ACC [92.46%]\n",
      "Epoch [2190/3000] Step [1/1] Loss: [0.1832] Train ACC [92.46%]\n",
      "Epoch [2220/3000] Step [1/1] Loss: [0.1831] Train ACC [92.78%]\n",
      "Epoch [2250/3000] Step [1/1] Loss: [0.1823] Train ACC [92.62%]\n",
      "Epoch [2280/3000] Step [1/1] Loss: [0.1818] Train ACC [92.30%]\n",
      "Epoch [2310/3000] Step [1/1] Loss: [0.1816] Train ACC [92.30%]\n",
      "Epoch [2340/3000] Step [1/1] Loss: [0.1807] Train ACC [92.46%]\n",
      "Epoch [2370/3000] Step [1/1] Loss: [0.1802] Train ACC [92.62%]\n",
      "Epoch [2400/3000] Step [1/1] Loss: [0.1793] Train ACC [92.62%]\n",
      "Epoch [2430/3000] Step [1/1] Loss: [0.1791] Train ACC [92.46%]\n",
      "Epoch [2460/3000] Step [1/1] Loss: [0.1785] Train ACC [92.78%]\n",
      "Epoch [2490/3000] Step [1/1] Loss: [0.1779] Train ACC [92.78%]\n",
      "Epoch [2520/3000] Step [1/1] Loss: [0.1772] Train ACC [93.10%]\n",
      "Epoch [2550/3000] Step [1/1] Loss: [0.1764] Train ACC [92.94%]\n",
      "Epoch [2580/3000] Step [1/1] Loss: [0.1760] Train ACC [92.62%]\n",
      "Epoch [2610/3000] Step [1/1] Loss: [0.1756] Train ACC [92.78%]\n",
      "Epoch [2640/3000] Step [1/1] Loss: [0.1748] Train ACC [92.94%]\n",
      "Epoch [2670/3000] Step [1/1] Loss: [0.1744] Train ACC [92.94%]\n",
      "Epoch [2700/3000] Step [1/1] Loss: [0.1742] Train ACC [92.78%]\n",
      "Epoch [2730/3000] Step [1/1] Loss: [0.1735] Train ACC [92.62%]\n",
      "Epoch [2760/3000] Step [1/1] Loss: [0.1730] Train ACC [93.10%]\n",
      "Epoch [2790/3000] Step [1/1] Loss: [0.1731] Train ACC [92.62%]\n",
      "Epoch [2820/3000] Step [1/1] Loss: [0.1720] Train ACC [92.94%]\n",
      "Epoch [2850/3000] Step [1/1] Loss: [0.1717] Train ACC [93.42%]\n",
      "Epoch [2880/3000] Step [1/1] Loss: [0.1714] Train ACC [92.94%]\n",
      "Epoch [2910/3000] Step [1/1] Loss: [0.1714] Train ACC [92.78%]\n",
      "Epoch [2940/3000] Step [1/1] Loss: [0.1705] Train ACC [93.10%]\n",
      "Epoch [2970/3000] Step [1/1] Loss: [0.1704] Train ACC [93.10%]\n",
      "Epoch [3000/3000] Step [1/1] Loss: [0.1699] Train ACC [93.10%]\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "        \n",
    "        #Forward \n",
    "        y_output = model(X_batch)\n",
    "        loss = criterion(y_output, y_batch) #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n",
    "        \n",
    "        #Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #misc (acc 계산, etc) \n",
    "        y_pred = torch.max(y_output, 1)[1]\n",
    "        acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n",
    "        loss_list.append(loss.item())\n",
    "        acc_list.append(acc)\n",
    "\n",
    "    if (epoch+1) % 30 == 0:\n",
    "        print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n",
    "                                                                                   i+1, len(train_loader), loss.item(), acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "nt8_rTpKIWnn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x251154fc5c8>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UNyiCLTaIWno"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2512b4dfdc8>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo1y3M1DIWno"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQnDA546IWno"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T08:26:31.968976Z",
     "start_time": "2018-10-28T08:26:31.839523Z"
    },
    "id": "rc7KvXo9IWno"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: [58.21%]\n"
     ]
    }
   ],
   "source": [
    "test_y_pred = []\n",
    "test_acc_list = []\n",
    "with torch.no_grad():\n",
    "\n",
    "    for X_batch, y_batch in test_loader:    \n",
    "        #Forward\n",
    "        y_output = model(X_batch)\n",
    "        \n",
    "        #misc (acc 계산, etc) \n",
    "        y_pred = torch.max(y_output, 1)[1]\n",
    "        test_y_pred.append(y_pred) ##\n",
    "        \n",
    "        acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n",
    "        test_acc_list.append(acc)\n",
    "    test_acc = np.mean(test_acc_list)\n",
    "print('Test ACC: [{:.2f}%]'.format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Nprk6vB0IWnp"
   },
   "outputs": [],
   "source": [
    "# 위에 테스트는 정확도 90퍼정도 나왔는데 아래에서는 72퍼나왔는거 과적합이 일어날건로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Fyd662TbIWnp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268,\n",
       " [tensor([0]),\n",
       "  tensor([1]),\n",
       "  tensor([1]),\n",
       "  tensor([1]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([0]),\n",
       "  tensor([0])])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_y_pred), test_y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CNq2fjt0IWnp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jxs6VnCWIWnp"
   },
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xHUn8ZzFIWnp"
   },
   "outputs": [],
   "source": [
    "class Binary_Classification_layer(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(Binary_Classification_layer, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.Layer_1 = nn.Sequential(\n",
    "                                nn.Linear(num_features, 30),\n",
    "                                nn.ReLU()\n",
    "                            )\n",
    "        self.Layer_2 = nn.Sequential(\n",
    "                                nn.Linear(30, 15),\n",
    "                                nn.ReLU()\n",
    "                            )\n",
    "        self.Layer_3 = nn.Sequential(\n",
    "                                nn.Linear(15, 8),\n",
    "                                nn.ReLU()\n",
    "                            )\n",
    "        \n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################\n",
    "        \n",
    "        self.Layer_out = nn.Linear(8, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.Layer_1(inputs)  \n",
    "        x = self.Layer_2(x)\n",
    "        x = self.Layer_3(x)\n",
    "       \n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################    \n",
    "        \n",
    "        x = self.Layer_out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "-t6i8Xn_IWnq"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 480\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "model = Binary_Classification_layer(num_features=6, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # https://pytorch.org/docs/stable/nn.html\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LU_anXJlIWnq",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/5000] Step [2/2] Loss: [0.6434] Train avg ACC [62.14%] Test ACC [63.36%]\n",
      "Epoch [60/5000] Step [2/2] Loss: [0.5400] Train avg ACC [71.45%] Test ACC [72.14%]\n",
      "Epoch [90/5000] Step [2/2] Loss: [0.4939] Train avg ACC [75.15%] Test ACC [75.77%]\n",
      "Epoch [120/5000] Step [2/2] Loss: [0.4683] Train avg ACC [77.22%] Test ACC [77.80%]\n",
      "Epoch [150/5000] Step [2/2] Loss: [0.4528] Train avg ACC [78.49%] Test ACC [78.92%]\n",
      "Epoch [180/5000] Step [2/2] Loss: [0.4402] Train avg ACC [79.46%] Test ACC [79.93%]\n",
      "Epoch [210/5000] Step [2/2] Loss: [0.4307] Train avg ACC [80.09%] Test ACC [80.46%]\n",
      "Epoch [240/5000] Step [2/2] Loss: [0.4240] Train avg ACC [80.57%] Test ACC [80.87%]\n",
      "Epoch [270/5000] Step [2/2] Loss: [0.4177] Train avg ACC [80.97%] Test ACC [81.23%]\n",
      "Epoch [300/5000] Step [2/2] Loss: [0.4118] Train avg ACC [81.29%] Test ACC [81.54%]\n",
      "Epoch [330/5000] Step [2/2] Loss: [0.4072] Train avg ACC [81.59%] Test ACC [81.80%]\n",
      "Epoch [360/5000] Step [2/2] Loss: [0.4028] Train avg ACC [81.88%] Test ACC [82.12%]\n",
      "Epoch [390/5000] Step [2/2] Loss: [0.3988] Train avg ACC [82.14%] Test ACC [82.34%]\n",
      "Epoch [420/5000] Step [2/2] Loss: [0.3948] Train avg ACC [82.36%] Test ACC [82.56%]\n",
      "Epoch [450/5000] Step [2/2] Loss: [0.3912] Train avg ACC [82.56%] Test ACC [82.76%]\n",
      "Epoch [480/5000] Step [2/2] Loss: [0.3874] Train avg ACC [82.77%] Test ACC [83.00%]\n",
      "Epoch [510/5000] Step [2/2] Loss: [0.3842] Train avg ACC [82.94%] Test ACC [83.17%]\n",
      "Epoch [540/5000] Step [2/2] Loss: [0.3813] Train avg ACC [83.10%] Test ACC [83.33%]\n",
      "Epoch [570/5000] Step [2/2] Loss: [0.3784] Train avg ACC [83.26%] Test ACC [83.49%]\n",
      "Epoch [600/5000] Step [2/2] Loss: [0.3757] Train avg ACC [83.37%] Test ACC [83.58%]\n",
      "Epoch [630/5000] Step [2/2] Loss: [0.3728] Train avg ACC [83.51%] Test ACC [83.74%]\n",
      "Epoch [660/5000] Step [2/2] Loss: [0.3702] Train avg ACC [83.65%] Test ACC [83.88%]\n",
      "Epoch [690/5000] Step [2/2] Loss: [0.3678] Train avg ACC [83.78%] Test ACC [84.00%]\n",
      "Epoch [720/5000] Step [2/2] Loss: [0.3652] Train avg ACC [83.92%] Test ACC [84.17%]\n",
      "Epoch [750/5000] Step [2/2] Loss: [0.3628] Train avg ACC [84.05%] Test ACC [84.31%]\n",
      "Epoch [780/5000] Step [2/2] Loss: [0.3605] Train avg ACC [84.17%] Test ACC [84.44%]\n",
      "Epoch [810/5000] Step [2/2] Loss: [0.3583] Train avg ACC [84.28%] Test ACC [84.55%]\n",
      "Epoch [840/5000] Step [2/2] Loss: [0.3563] Train avg ACC [84.38%] Test ACC [84.63%]\n",
      "Epoch [870/5000] Step [2/2] Loss: [0.3544] Train avg ACC [84.48%] Test ACC [84.71%]\n",
      "Epoch [900/5000] Step [2/2] Loss: [0.3523] Train avg ACC [84.58%] Test ACC [84.83%]\n",
      "Epoch [930/5000] Step [2/2] Loss: [0.3502] Train avg ACC [84.68%] Test ACC [84.93%]\n",
      "Epoch [960/5000] Step [2/2] Loss: [0.3484] Train avg ACC [84.76%] Test ACC [85.00%]\n",
      "Epoch [990/5000] Step [2/2] Loss: [0.3465] Train avg ACC [84.84%] Test ACC [85.08%]\n",
      "Epoch [1020/5000] Step [2/2] Loss: [0.3447] Train avg ACC [84.93%] Test ACC [85.15%]\n",
      "Epoch [1050/5000] Step [2/2] Loss: [0.3429] Train avg ACC [85.01%] Test ACC [85.24%]\n",
      "Epoch [1080/5000] Step [2/2] Loss: [0.3411] Train avg ACC [85.09%] Test ACC [85.32%]\n",
      "Epoch [1110/5000] Step [2/2] Loss: [0.3394] Train avg ACC [85.16%] Test ACC [85.39%]\n",
      "Epoch [1140/5000] Step [2/2] Loss: [0.3375] Train avg ACC [85.24%] Test ACC [85.48%]\n",
      "Epoch [1170/5000] Step [2/2] Loss: [0.3359] Train avg ACC [85.32%] Test ACC [85.56%]\n",
      "Epoch [1200/5000] Step [2/2] Loss: [0.3344] Train avg ACC [85.38%] Test ACC [85.61%]\n",
      "Epoch [1230/5000] Step [2/2] Loss: [0.3328] Train avg ACC [85.44%] Test ACC [85.68%]\n",
      "Epoch [1260/5000] Step [2/2] Loss: [0.3312] Train avg ACC [85.51%] Test ACC [85.75%]\n",
      "Epoch [1290/5000] Step [2/2] Loss: [0.3298] Train avg ACC [85.57%] Test ACC [85.79%]\n",
      "Epoch [1320/5000] Step [2/2] Loss: [0.3283] Train avg ACC [85.63%] Test ACC [85.86%]\n",
      "Epoch [1350/5000] Step [2/2] Loss: [0.3268] Train avg ACC [85.69%] Test ACC [85.91%]\n",
      "Epoch [1380/5000] Step [2/2] Loss: [0.3254] Train avg ACC [85.76%] Test ACC [85.97%]\n",
      "Epoch [1410/5000] Step [2/2] Loss: [0.3240] Train avg ACC [85.82%] Test ACC [86.03%]\n",
      "Epoch [1440/5000] Step [2/2] Loss: [0.3226] Train avg ACC [85.89%] Test ACC [86.11%]\n",
      "Epoch [1470/5000] Step [2/2] Loss: [0.3212] Train avg ACC [85.95%] Test ACC [86.17%]\n",
      "Epoch [1500/5000] Step [2/2] Loss: [0.3199] Train avg ACC [86.00%] Test ACC [86.22%]\n",
      "Epoch [1530/5000] Step [2/2] Loss: [0.3187] Train avg ACC [86.06%] Test ACC [86.27%]\n",
      "Epoch [1560/5000] Step [2/2] Loss: [0.3174] Train avg ACC [86.12%] Test ACC [86.33%]\n",
      "Epoch [1590/5000] Step [2/2] Loss: [0.3161] Train avg ACC [86.17%] Test ACC [86.39%]\n",
      "Epoch [1620/5000] Step [2/2] Loss: [0.3148] Train avg ACC [86.23%] Test ACC [86.46%]\n",
      "Epoch [1650/5000] Step [2/2] Loss: [0.3136] Train avg ACC [86.29%] Test ACC [86.51%]\n",
      "Epoch [1680/5000] Step [2/2] Loss: [0.3124] Train avg ACC [86.34%] Test ACC [86.56%]\n",
      "Epoch [1710/5000] Step [2/2] Loss: [0.3112] Train avg ACC [86.39%] Test ACC [86.61%]\n",
      "Epoch [1740/5000] Step [2/2] Loss: [0.3101] Train avg ACC [86.44%] Test ACC [86.66%]\n",
      "Epoch [1770/5000] Step [2/2] Loss: [0.3090] Train avg ACC [86.48%] Test ACC [86.71%]\n",
      "Epoch [1800/5000] Step [2/2] Loss: [0.3079] Train avg ACC [86.53%] Test ACC [86.75%]\n",
      "Epoch [1830/5000] Step [2/2] Loss: [0.3068] Train avg ACC [86.58%] Test ACC [86.81%]\n",
      "Epoch [1860/5000] Step [2/2] Loss: [0.3057] Train avg ACC [86.62%] Test ACC [86.85%]\n",
      "Epoch [1890/5000] Step [2/2] Loss: [0.3047] Train avg ACC [86.67%] Test ACC [86.90%]\n",
      "Epoch [1920/5000] Step [2/2] Loss: [0.3037] Train avg ACC [86.71%] Test ACC [86.93%]\n",
      "Epoch [1950/5000] Step [2/2] Loss: [0.3027] Train avg ACC [86.75%] Test ACC [86.97%]\n",
      "Epoch [1980/5000] Step [2/2] Loss: [0.3017] Train avg ACC [86.79%] Test ACC [87.01%]\n",
      "Epoch [2010/5000] Step [2/2] Loss: [0.3007] Train avg ACC [86.83%] Test ACC [87.04%]\n",
      "Epoch [2040/5000] Step [2/2] Loss: [0.2998] Train avg ACC [86.87%] Test ACC [87.09%]\n",
      "Epoch [2070/5000] Step [2/2] Loss: [0.2988] Train avg ACC [86.91%] Test ACC [87.13%]\n",
      "Epoch [2100/5000] Step [2/2] Loss: [0.2979] Train avg ACC [86.95%] Test ACC [87.17%]\n",
      "Epoch [2130/5000] Step [2/2] Loss: [0.2970] Train avg ACC [86.99%] Test ACC [87.21%]\n",
      "Epoch [2160/5000] Step [2/2] Loss: [0.2960] Train avg ACC [87.03%] Test ACC [87.26%]\n",
      "Epoch [2190/5000] Step [2/2] Loss: [0.2951] Train avg ACC [87.07%] Test ACC [87.29%]\n",
      "Epoch [2220/5000] Step [2/2] Loss: [0.2942] Train avg ACC [87.11%] Test ACC [87.33%]\n",
      "Epoch [2250/5000] Step [2/2] Loss: [0.2934] Train avg ACC [87.15%] Test ACC [87.37%]\n",
      "Epoch [2280/5000] Step [2/2] Loss: [0.2925] Train avg ACC [87.19%] Test ACC [87.42%]\n",
      "Epoch [2310/5000] Step [2/2] Loss: [0.2917] Train avg ACC [87.22%] Test ACC [87.45%]\n",
      "Epoch [2340/5000] Step [2/2] Loss: [0.2909] Train avg ACC [87.25%] Test ACC [87.49%]\n",
      "Epoch [2370/5000] Step [2/2] Loss: [0.2901] Train avg ACC [87.29%] Test ACC [87.52%]\n",
      "Epoch [2400/5000] Step [2/2] Loss: [0.2893] Train avg ACC [87.32%] Test ACC [87.55%]\n",
      "Epoch [2430/5000] Step [2/2] Loss: [0.2885] Train avg ACC [87.36%] Test ACC [87.59%]\n",
      "Epoch [2460/5000] Step [2/2] Loss: [0.2877] Train avg ACC [87.39%] Test ACC [87.63%]\n",
      "Epoch [2490/5000] Step [2/2] Loss: [0.2869] Train avg ACC [87.43%] Test ACC [87.67%]\n",
      "Epoch [2520/5000] Step [2/2] Loss: [0.2862] Train avg ACC [87.46%] Test ACC [87.70%]\n",
      "Epoch [2550/5000] Step [2/2] Loss: [0.2855] Train avg ACC [87.50%] Test ACC [87.73%]\n",
      "Epoch [2580/5000] Step [2/2] Loss: [0.2847] Train avg ACC [87.53%] Test ACC [87.77%]\n",
      "Epoch [2610/5000] Step [2/2] Loss: [0.2840] Train avg ACC [87.56%] Test ACC [87.80%]\n",
      "Epoch [2640/5000] Step [2/2] Loss: [0.2833] Train avg ACC [87.59%] Test ACC [87.83%]\n",
      "Epoch [2670/5000] Step [2/2] Loss: [0.2826] Train avg ACC [87.62%] Test ACC [87.87%]\n",
      "Epoch [2700/5000] Step [2/2] Loss: [0.2819] Train avg ACC [87.65%] Test ACC [87.90%]\n",
      "Epoch [2730/5000] Step [2/2] Loss: [0.2812] Train avg ACC [87.68%] Test ACC [87.93%]\n",
      "Epoch [2760/5000] Step [2/2] Loss: [0.2806] Train avg ACC [87.71%] Test ACC [87.96%]\n",
      "Epoch [2790/5000] Step [2/2] Loss: [0.2799] Train avg ACC [87.75%] Test ACC [87.99%]\n",
      "Epoch [2820/5000] Step [2/2] Loss: [0.2792] Train avg ACC [87.78%] Test ACC [88.02%]\n",
      "Epoch [2850/5000] Step [2/2] Loss: [0.2786] Train avg ACC [87.81%] Test ACC [88.05%]\n",
      "Epoch [2880/5000] Step [2/2] Loss: [0.2779] Train avg ACC [87.84%] Test ACC [88.09%]\n",
      "Epoch [2910/5000] Step [2/2] Loss: [0.2772] Train avg ACC [87.87%] Test ACC [88.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2940/5000] Step [2/2] Loss: [0.2766] Train avg ACC [87.90%] Test ACC [88.15%]\n",
      "Epoch [2970/5000] Step [2/2] Loss: [0.2760] Train avg ACC [87.93%] Test ACC [88.18%]\n",
      "Epoch [3000/5000] Step [2/2] Loss: [0.2754] Train avg ACC [87.95%] Test ACC [88.21%]\n",
      "Epoch [3030/5000] Step [2/2] Loss: [0.2748] Train avg ACC [87.98%] Test ACC [88.23%]\n",
      "Epoch [3060/5000] Step [2/2] Loss: [0.2742] Train avg ACC [88.01%] Test ACC [88.26%]\n",
      "Epoch [3090/5000] Step [2/2] Loss: [0.2737] Train avg ACC [88.03%] Test ACC [88.28%]\n",
      "Epoch [3120/5000] Step [2/2] Loss: [0.2731] Train avg ACC [88.06%] Test ACC [88.30%]\n",
      "Epoch [3150/5000] Step [2/2] Loss: [0.2726] Train avg ACC [88.08%] Test ACC [88.32%]\n",
      "Epoch [3180/5000] Step [2/2] Loss: [0.2720] Train avg ACC [88.11%] Test ACC [88.35%]\n",
      "Epoch [3210/5000] Step [2/2] Loss: [0.2714] Train avg ACC [88.14%] Test ACC [88.38%]\n",
      "Epoch [3240/5000] Step [2/2] Loss: [0.2709] Train avg ACC [88.16%] Test ACC [88.40%]\n",
      "Epoch [3270/5000] Step [2/2] Loss: [0.2704] Train avg ACC [88.18%] Test ACC [88.43%]\n",
      "Epoch [3300/5000] Step [2/2] Loss: [0.2699] Train avg ACC [88.21%] Test ACC [88.45%]\n",
      "Epoch [3330/5000] Step [2/2] Loss: [0.2693] Train avg ACC [88.23%] Test ACC [88.48%]\n",
      "Epoch [3360/5000] Step [2/2] Loss: [0.2688] Train avg ACC [88.26%] Test ACC [88.50%]\n",
      "Epoch [3390/5000] Step [2/2] Loss: [0.2683] Train avg ACC [88.28%] Test ACC [88.52%]\n",
      "Epoch [3420/5000] Step [2/2] Loss: [0.2678] Train avg ACC [88.30%] Test ACC [88.54%]\n",
      "Epoch [3450/5000] Step [2/2] Loss: [0.2673] Train avg ACC [88.32%] Test ACC [88.57%]\n",
      "Epoch [3480/5000] Step [2/2] Loss: [0.2668] Train avg ACC [88.35%] Test ACC [88.59%]\n",
      "Epoch [3510/5000] Step [2/2] Loss: [0.2663] Train avg ACC [88.37%] Test ACC [88.61%]\n",
      "Epoch [3540/5000] Step [2/2] Loss: [0.2658] Train avg ACC [88.39%] Test ACC [88.63%]\n",
      "Epoch [3570/5000] Step [2/2] Loss: [0.2653] Train avg ACC [88.41%] Test ACC [88.65%]\n",
      "Epoch [3600/5000] Step [2/2] Loss: [0.2649] Train avg ACC [88.43%] Test ACC [88.67%]\n",
      "Epoch [3630/5000] Step [2/2] Loss: [0.2644] Train avg ACC [88.45%] Test ACC [88.69%]\n",
      "Epoch [3660/5000] Step [2/2] Loss: [0.2639] Train avg ACC [88.47%] Test ACC [88.70%]\n",
      "Epoch [3690/5000] Step [2/2] Loss: [0.2635] Train avg ACC [88.49%] Test ACC [88.72%]\n",
      "Epoch [3720/5000] Step [2/2] Loss: [0.2630] Train avg ACC [88.51%] Test ACC [88.75%]\n",
      "Epoch [3750/5000] Step [2/2] Loss: [0.2625] Train avg ACC [88.53%] Test ACC [88.77%]\n",
      "Epoch [3780/5000] Step [2/2] Loss: [0.2621] Train avg ACC [88.55%] Test ACC [88.79%]\n",
      "Epoch [3810/5000] Step [2/2] Loss: [0.2617] Train avg ACC [88.57%] Test ACC [88.81%]\n",
      "Epoch [3840/5000] Step [2/2] Loss: [0.2612] Train avg ACC [88.59%] Test ACC [88.83%]\n",
      "Epoch [3870/5000] Step [2/2] Loss: [0.2608] Train avg ACC [88.61%] Test ACC [88.85%]\n",
      "Epoch [3900/5000] Step [2/2] Loss: [0.2603] Train avg ACC [88.63%] Test ACC [88.87%]\n",
      "Epoch [3930/5000] Step [2/2] Loss: [0.2599] Train avg ACC [88.65%] Test ACC [88.89%]\n",
      "Epoch [3960/5000] Step [2/2] Loss: [0.2595] Train avg ACC [88.67%] Test ACC [88.91%]\n",
      "Epoch [3990/5000] Step [2/2] Loss: [0.2591] Train avg ACC [88.69%] Test ACC [88.93%]\n",
      "Epoch [4020/5000] Step [2/2] Loss: [0.2587] Train avg ACC [88.70%] Test ACC [88.95%]\n",
      "Epoch [4050/5000] Step [2/2] Loss: [0.2583] Train avg ACC [88.72%] Test ACC [88.96%]\n",
      "Epoch [4080/5000] Step [2/2] Loss: [0.2579] Train avg ACC [88.74%] Test ACC [88.98%]\n",
      "Epoch [4110/5000] Step [2/2] Loss: [0.2575] Train avg ACC [88.75%] Test ACC [88.99%]\n",
      "Epoch [4140/5000] Step [2/2] Loss: [0.2571] Train avg ACC [88.77%] Test ACC [89.00%]\n",
      "Epoch [4170/5000] Step [2/2] Loss: [0.2567] Train avg ACC [88.79%] Test ACC [89.02%]\n",
      "Epoch [4200/5000] Step [2/2] Loss: [0.2563] Train avg ACC [88.80%] Test ACC [89.04%]\n",
      "Epoch [4230/5000] Step [2/2] Loss: [0.2559] Train avg ACC [88.82%] Test ACC [89.06%]\n",
      "Epoch [4260/5000] Step [2/2] Loss: [0.2555] Train avg ACC [88.84%] Test ACC [89.08%]\n",
      "Epoch [4290/5000] Step [2/2] Loss: [0.2551] Train avg ACC [88.86%] Test ACC [89.09%]\n",
      "Epoch [4320/5000] Step [2/2] Loss: [0.2547] Train avg ACC [88.87%] Test ACC [89.11%]\n",
      "Epoch [4350/5000] Step [2/2] Loss: [0.2544] Train avg ACC [88.89%] Test ACC [89.12%]\n",
      "Epoch [4380/5000] Step [2/2] Loss: [0.2540] Train avg ACC [88.91%] Test ACC [89.14%]\n",
      "Epoch [4410/5000] Step [2/2] Loss: [0.2536] Train avg ACC [88.92%] Test ACC [89.16%]\n",
      "Epoch [4440/5000] Step [2/2] Loss: [0.2532] Train avg ACC [88.94%] Test ACC [89.18%]\n",
      "Epoch [4470/5000] Step [2/2] Loss: [0.2529] Train avg ACC [88.95%] Test ACC [89.20%]\n",
      "Epoch [4500/5000] Step [2/2] Loss: [0.2525] Train avg ACC [88.97%] Test ACC [89.21%]\n",
      "Epoch [4530/5000] Step [2/2] Loss: [0.2522] Train avg ACC [88.98%] Test ACC [89.23%]\n",
      "Epoch [4560/5000] Step [2/2] Loss: [0.2518] Train avg ACC [89.00%] Test ACC [89.24%]\n",
      "Epoch [4590/5000] Step [2/2] Loss: [0.2515] Train avg ACC [89.02%] Test ACC [89.26%]\n",
      "Epoch [4620/5000] Step [2/2] Loss: [0.2511] Train avg ACC [89.03%] Test ACC [89.27%]\n",
      "Epoch [4650/5000] Step [2/2] Loss: [0.2507] Train avg ACC [89.05%] Test ACC [89.29%]\n",
      "Epoch [4680/5000] Step [2/2] Loss: [0.2504] Train avg ACC [89.06%] Test ACC [89.30%]\n",
      "Epoch [4710/5000] Step [2/2] Loss: [0.2500] Train avg ACC [89.08%] Test ACC [89.32%]\n",
      "Epoch [4740/5000] Step [2/2] Loss: [0.2497] Train avg ACC [89.09%] Test ACC [89.33%]\n",
      "Epoch [4770/5000] Step [2/2] Loss: [0.2494] Train avg ACC [89.11%] Test ACC [89.34%]\n",
      "Epoch [4800/5000] Step [2/2] Loss: [0.2490] Train avg ACC [89.12%] Test ACC [89.36%]\n",
      "Epoch [4830/5000] Step [2/2] Loss: [0.2487] Train avg ACC [89.13%] Test ACC [89.37%]\n",
      "Epoch [4860/5000] Step [2/2] Loss: [0.2483] Train avg ACC [89.15%] Test ACC [89.39%]\n",
      "Epoch [4890/5000] Step [2/2] Loss: [0.2480] Train avg ACC [89.16%] Test ACC [89.40%]\n",
      "Epoch [4920/5000] Step [2/2] Loss: [0.2477] Train avg ACC [89.18%] Test ACC [89.42%]\n",
      "Epoch [4950/5000] Step [2/2] Loss: [0.2473] Train avg ACC [89.19%] Test ACC [89.43%]\n",
      "Epoch [4980/5000] Step [2/2] Loss: [0.2470] Train avg ACC [89.20%] Test ACC [89.45%]\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # train\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader): \n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################ \n",
    "        \n",
    "        \n",
    "        #Forward \n",
    "        y_output = model(X_batch)\n",
    "        loss = criterion(y_output, y_batch) #CELoss: The input is expected to contain raw, unnormalized scores for each class.\n",
    "        \n",
    "        #Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #misc (acc 계산, etc) \n",
    "        y_pred = torch.max(y_output, 1)[1]\n",
    "        train_acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n",
    "        \n",
    "        train_loss_list.append(loss.item())\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "    \n",
    "        \n",
    "    # test\n",
    "    with torch.no_grad():\n",
    "        ################################################\n",
    "        #       TODO                                   #\n",
    "        ################################################ \n",
    "        #Forward\n",
    "        y_output = model(X_batch)\n",
    "        \n",
    "        #misc (acc 계산, etc) \n",
    "        y_pred = torch.max(y_output, 1)[1]\n",
    "\n",
    "        \n",
    "        test_acc = accuracy_score(y_pred.data.cpu(), y_batch.data.cpu())\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (epoch+1) % 30 == 0:\n",
    "        print('Epoch [{}/{}] Step [{}/{}] Loss: [{:.4f}] Train avg ACC [{:.2f}%] Test ACC [{:.2f}%]'.format(epoch+1, EPOCHS, \\\n",
    "                                                                                   i+1, len(train_loader), np.mean(train_loss_list), \\\n",
    "                                                                                                        np.mean(train_acc_list)*100, np.mean(test_acc_list)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "3_Binary_Classification_Neural_Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
