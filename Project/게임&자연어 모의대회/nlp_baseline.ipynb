{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68696f7d-99f7-4a1b-97b1-882d0c5565e9",
   "metadata": {},
   "source": [
    "# [모의 캐글 - 게임] 비매너 댓글 식별 \n",
    "\n",
    "- 자연어 multi label classification 과제\n",
    "- 작성자 : MNC Sukyung Kim (skkim@mnc.ai)\n",
    "\n",
    "참고 논문 : \n",
    "- [BERT: Pre-training of Deep Bidirectional Transformers for\n",
    "Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "- [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa42a1-848b-4d3b-b13e-b65cf0972404",
   "metadata": {},
   "source": [
    "# 1. 환경 설정 및 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c0e90b-6f4c-45fd-b83c-140dcde11d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff15bef2-c669-4cb1-bf76-256154c4858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from attrdict import AttrDict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import *\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "from transformers import logging, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "from transformers import ( \n",
    "    BertConfig,\n",
    "    ElectraConfig\n",
    ")\n",
    "\n",
    "### v2 에서 라이브러리 추가됨\n",
    "# 실험에 사용하실 모델 라이브러리를 추가하시는 걸 잊지 마세요!\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,  \n",
    "    AutoTokenizer,\n",
    "    ElectraTokenizer,\n",
    "    AlbertTokenizer\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    AutoModel, \n",
    "    ElectraForSequenceClassification,\n",
    "    BertForSequenceClassification,\n",
    "    AlbertForSequenceClassification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c95b317-b37f-4c59-8eaf-25ce048eb753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs:  1\n",
      "Does GPU exist? :  True\n"
     ]
    }
   ],
   "source": [
    "# 사용할 GPU 지정\n",
    "print(\"number of GPUs: \", torch.cuda.device_count())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"Does GPU exist? : \", use_cuda)\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ffbcad1-d170-462f-807d-41760e65f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True 일 때 코드를 실행하면 example 등을 보여줌\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7484847-924d-4f99-8b41-190ae4f192e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file loaded.\n",
      "beomi/KcELECTRA-base\n"
     ]
    }
   ],
   "source": [
    "# config 파일 불러오기\n",
    "config_path = os.path.join('config.json')\n",
    "\n",
    "def set_config(config_path):\n",
    "    if os.path.lexists(config_path):\n",
    "        with open(config_path) as f:\n",
    "            args = AttrDict(json.load(f))\n",
    "            print(\"config file loaded.\")\n",
    "            print(args.pretrained_model)\n",
    "    else:\n",
    "        assert False, 'config json file cannot be found.. please check the path again.'\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "# 코드 중간중간에 끼워넣어 리셋 가능\n",
    "args = set_config(config_path)\n",
    "\n",
    "# 결과 저장 폴더 미리 생성\n",
    "os.makedirs(args.result_dir, exist_ok=True)\n",
    "os.makedirs(args.config_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04c99c-208b-46a1-82cd-a7c9c776c8ad",
   "metadata": {},
   "source": [
    "# 2. EDA 및 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87df6631-40e2-4c33-bacc-6548f9459d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "# data 경로 설정  \n",
    "train_path = os.path.join(args.data_dir,'train.csv')\n",
    "\n",
    "print(\"train 데이터 경로가 올바른가요? : \", os.path.lexists(train_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3123598-d707-467a-a380-99644a9a3637",
   "metadata": {},
   "source": [
    "### 2-1. Train 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d5cb19-0e61-4358-9a9b-c690cbe8c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"   \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만...   \n",
       "2             \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"   \n",
       "3               \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"   \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의...   \n",
       "\n",
       "                                             comment    bias  hate  \n",
       "0                                     김태리 정말 연기잘해 진짜    none  none  \n",
       "1                           공효진 발연기나이질생각이읍던데 왜계속주연일까    none  hate  \n",
       "2  누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에...  others  hate  \n",
       "3                                           일본 축구 져라    none  none  \n",
       "4                         난 절대로 임현주 욕하는인간이랑은 안논다 @.@    none  none  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path, encoding = 'UTF-8-SIG')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dce65d19-028f-4dc6-96e2-a9ac0949b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### v2 에서 추가됨\n",
    "\n",
    "# title 중 가장 긴 타이틀 길이\n",
    "# max_len_title = np.max(train_df['title'].str.len())\n",
    "# max_len_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b449c22-6103-4cb9-9900-a2c3f7a7a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment 중 가장 긴 타이틀 길이\n",
    "# max_len_comment=np.max(train_df['comment'].str.len())\n",
    "# max_len_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f674ee-0184-4635-b353-d9975649fb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 길이가 128이 넘는 코멘트 확인\n",
    "# train_df['comment'][train_df['comment'].str.len()>128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10dee23-db6d-4fce-8b06-054c3457adaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ecb32ed-e7f9-4640-89c2-87005a9aed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"bias classes: \", train_df.bias.unique())\n",
    "# print(\"hate classes: \", train_df.hate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faecbd1a-82ee-40ed-b81a-2984674b669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(train_df.bias, train_df.hate, margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d3802b-a501-4adc-9f9a-6968df7684d3",
   "metadata": {},
   "source": [
    "### 2-2. Test 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86211318-bfaa-47c7-9653-63a13905dc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 데이터 경로가 올바른가요? :  True\n"
     ]
    }
   ],
   "source": [
    "test_path = os.path.join(args.data_dir,'test.csv')\n",
    "print(\"test 데이터 경로가 올바른가요? : \", os.path.lexists(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a713f829-09c9-468a-8266-4bd555e29906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]</td>\n",
       "      <td>둘다 넘 좋다~행복하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]</td>\n",
       "      <td>근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]</td>\n",
       "      <td>누군데 얘네?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"</td>\n",
       "      <td>쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]</td>\n",
       "      <td>안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title  \\\n",
       "0   0        류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]   \n",
       "1   1  \"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]   \n",
       "2   2     입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]   \n",
       "3   3        아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"   \n",
       "4   4         구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]   \n",
       "\n",
       "                                             comment  \n",
       "0                                      둘다 넘 좋다~행복하세요  \n",
       "1               근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데  \n",
       "2                                            누군데 얘네?  \n",
       "3  쑈 하지마라 짜식아!음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다.슬금슬금 ...  \n",
       "4  안검하수 가지고 있는 분께 희망을 주고 싶은건가요? 수술하면 이렇게 자연스러워진다고...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ad5fbb7-acb5-47cb-b0f3-b220bf78ab67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb5aa8-6284-4066-a69d-a1539c5287a5",
   "metadata": {},
   "source": [
    "### 2-3. 데이터 전처리 (Label Encoding)\n",
    "bias, hate 라벨들의 class를 정수로 변경하여 라벨 인코딩을 하기 위한 딕셔너리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11018420-84da-40ac-b892-4e47f20dd83f",
   "metadata": {},
   "source": [
    "- bias, hate 컬럼을 합쳐서 하나의 라벨로 만들기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a70c1c98-6b12-4e70-b038-e93e78764fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7058/3652881321.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51057622-e937-4558-855a-8230f2d4d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "# train_df[\"title\"] = train_df[\"title\"].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)\n",
    "# train_df[\"comment\"] = train_df[\"comment\"].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f974c4e0-7d14-4219-904f-17017b4a17e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"</td>\n",
       "      <td>공효진 발연기나이질생각이읍던데 왜계속주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에 감사하고 항상 좋은일만 가득하길~</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"</td>\n",
       "      <td>난 절대로 임현주 욕하는인간이랑은 안논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>\"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"</td>\n",
       "      <td>아니 근데.튜닝한사람은 프러포즈받지도.결혼도못함?ㅋㅋㅋ지들은 돈없어서 못하는것들이ㅋㅋㅋㅋ아이고배아퍼죽지ㅋ</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>\"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"</td>\n",
       "      <td>그러니깐 여자를 잘만나야되~징글징글한것들 만나면 인생 끝가지 돌아가게 되는듯.. 근데 왜 다들 김새롬 편을들어.,,? 미친것들이</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>\"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"</td>\n",
       "      <td>참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>[종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>\"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             title  \\\n",
       "0     \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"                     \n",
       "1     \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"       \n",
       "2     \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"                         \n",
       "3     \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"                           \n",
       "4     \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"   \n",
       "...                                                            ...   \n",
       "8362  \"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"                              \n",
       "8363  \"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"             \n",
       "8364  \"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"                    \n",
       "8365  [종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등                               \n",
       "8366  \"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"                             \n",
       "\n",
       "                                                                      comment  \\\n",
       "0     김태리 정말 연기잘해 진짜                                                            \n",
       "1     공효진 발연기나이질생각이읍던데 왜계속주연일까                                                  \n",
       "2     누구처럼 돈만 밝히는 저급인생은 살아가지마시길~~ 행복은 머니순이 아니니깐 작은거에 감사하고 항상 좋은일만 가득하길~         \n",
       "3     일본 축구 져라                                                                  \n",
       "4     난 절대로 임현주 욕하는인간이랑은 안논다 @.@                                                \n",
       "...                          ...                                                \n",
       "8362  아니 근데.튜닝한사람은 프러포즈받지도.결혼도못함?ㅋㅋㅋ지들은 돈없어서 못하는것들이ㅋㅋㅋㅋ아이고배아퍼죽지ㅋ                \n",
       "8363  그러니깐 여자를 잘만나야되~징글징글한것들 만나면 인생 끝가지 돌아가게 되는듯.. 근데 왜 다들 김새롬 편을들어.,,? 미친것들이   \n",
       "8364  참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡                      \n",
       "8365  재미가 없어요                                                                   \n",
       "8366  쭉 쉬세요                                                                     \n",
       "\n",
       "        bias  hate  \n",
       "0     none    none  \n",
       "1     none    hate  \n",
       "2     others  hate  \n",
       "3     none    none  \n",
       "4     none    none  \n",
       "...    ...     ...  \n",
       "8362  others  hate  \n",
       "8363  gender  hate  \n",
       "8364  none    none  \n",
       "8365  none    none  \n",
       "8366  none    hate  \n",
       "\n",
       "[8367 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136f4de8-60e4-4d4a-b33c-f58f9f3edc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment'][4467] = train_df['comment'][4467].replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f37cfa47-5668-4a7f-b4eb-30d0f0d097be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment'][5458] = train_df['comment'][5458].replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f674447a-8116-409a-86be-d88093ff6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment'] = train_df['comment'].replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f51a476f-7db0-445e-bcb1-c5e3e7f409a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'] = train_df['title'].replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c69d7b7d-a379-417c-a1f6-c7729a76060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment'] = train_df['comment'].replace('\"', '')\n",
    "# train_df['title'] = train_df['title'].replace('\"', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac720b8-6628-4af8-af29-588344852319",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['comment'] = train_df['comment'].str.strip('\"')\n",
    "# train_df['title'] = train_df['title'].str.strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07623a2a-a478-4b74-82bf-983f0cd73a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맞춤법 띄어쓰기 수정\n",
    "from hanspell import spell_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4740b14c-a2ec-4ae9-91b8-b88e73c3bb14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [title, comment, bias, hate]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['comment'].str.contains('혈액 암')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cfce7ce-885a-40ca-8eb0-3dab7909fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][2662] = train_df['title'][2662].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b502ed33-ed55-4d46-bae7-49c5a6e0613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][3412] =  train_df['title'][3412].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32d4d1a2-8d52-4b22-82cf-e09692572fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][4316] =  train_df['title'][4316].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e87104bd-b665-4055-b66e-f9494f491d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][5110] =  train_df['title'][5110].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fae7293-181f-4e6f-b5ca-f095bed19141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][5124] =  train_df['title'][5124].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7fb2cf63-3b2d-4274-9122-4f5ca9734903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][5854] =  train_df['title'][5854].replace('&', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fb4f9c1-d035-414a-9022-aa822d556c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['title'][3412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef1e2e3b-3cc0-4837-8952-2fd4d5d4298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['title'].str.contains('&')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30c10170-c76c-4991-91eb-c659e5516ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /train_df['comment'][660]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2eb64a3-0115-48f6-9f4d-a703e09431d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[train_df['comment'].str.contains('&')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1320f5aa-a5f4-48c6-a20f-d92865fc2777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_df)):    \n",
    "    # input_title = train_df['title'][i]\n",
    "    input_comment = train_df['comment'][i]\n",
    "\n",
    "    # spelled_title = spell_checker.check(input_title)\n",
    "    spelled_comment = spell_checker.check(input_comment)                       \n",
    "    \n",
    "    # checked_title = spelled_title.checked\n",
    "    checked_comment = spelled_comment.checked\n",
    "    \n",
    "    \n",
    "    # print(spelled_title.only_checked())\n",
    "    # print(spelled_comment.only_checked())\n",
    "    # train_df['title'][i] = checked_title \n",
    "    train_df['comment'][i] = checked_comment     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bcdadac-0882-48a9-88fd-2a0b2add1c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>\"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"</td>\n",
       "      <td>아니 근데. 튜닝한 사람은 프러포즈 받지도. 결혼도 못함? ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ᄏᄏᄏᄏ아이고 배 아파죽지ᄏ</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>\"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼~징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯.. 근데 왜 다들 김새롬 편을 들어.,,? 미친 것들이</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>\"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"</td>\n",
       "      <td>참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>[종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>\"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             title  \\\n",
       "0     \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"                     \n",
       "1     \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"       \n",
       "2     \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"                         \n",
       "3     \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"                           \n",
       "4     \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"   \n",
       "...                                                            ...   \n",
       "8362  \"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"                              \n",
       "8363  \"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"             \n",
       "8364  \"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"                    \n",
       "8365  [종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등                               \n",
       "8366  \"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"                             \n",
       "\n",
       "                                                                            comment  \\\n",
       "0     김태리 정말 연기 잘해 진짜                                                                 \n",
       "1     공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까                                                  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~          \n",
       "3     일본 축구 져라                                                                        \n",
       "4     난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@                                                    \n",
       "...                            ...                                                    \n",
       "8362  아니 근데. 튜닝한 사람은 프러포즈 받지도. 결혼도 못함? ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ᄏᄏᄏᄏ아이고 배 아파죽지ᄏ         \n",
       "8363  그러니깐 여자를 잘 만나야 돼~징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯.. 근데 왜 다들 김새롬 편을 들어.,,? 미친 것들이   \n",
       "8364  참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡                            \n",
       "8365  재미가 없어요                                                                         \n",
       "8366  쭉 쉬세요                                                                           \n",
       "\n",
       "        bias  hate  \n",
       "0     none    none  \n",
       "1     none    hate  \n",
       "2     others  hate  \n",
       "3     none    none  \n",
       "4     none    none  \n",
       "...    ...     ...  \n",
       "8362  others  hate  \n",
       "8363  gender  hate  \n",
       "8364  none    none  \n",
       "8365  none    none  \n",
       "8366  none    hate  \n",
       "\n",
       "[8367 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c2e8c556-a926-4734-b0f8-41cfa6cecf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복문자 제거\n",
    "# from soynlp.normalizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eebe63b-0553-4ea3-a4c3-c26dae1c1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train_df)):\n",
    "#     train_df['title'][i] = repeat_normalize(train_df['title'][i],  num_repeats=2)\n",
    "#     train_df['comment'][i] = repeat_normalize(train_df['comment'][i],  num_repeats=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46733b7a-00d0-4e1d-96f4-ab75cd9999cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8362</th>\n",
       "      <td>\"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"</td>\n",
       "      <td>아니 근데. 튜닝한 사람은 프러포즈 받지도. 결혼도 못함? ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ᄏᄏᄏᄏ아이고 배 아파죽지ᄏ</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8363</th>\n",
       "      <td>\"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"</td>\n",
       "      <td>그러니깐 여자를 잘 만나야 돼~징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯.. 근데 왜 다들 김새롬 편을 들어.,,? 미친 것들이</td>\n",
       "      <td>gender</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8364</th>\n",
       "      <td>\"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"</td>\n",
       "      <td>참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8365</th>\n",
       "      <td>[종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등</td>\n",
       "      <td>재미가 없어요</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8366</th>\n",
       "      <td>\"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"</td>\n",
       "      <td>쭉 쉬세요</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8367 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             title  \\\n",
       "0     \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"                     \n",
       "1     \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"       \n",
       "2     \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"                         \n",
       "3     \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"                           \n",
       "4     \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"   \n",
       "...                                                            ...   \n",
       "8362  \"배우 이필립, SNS 스타 연인에게 초호화 프러포즈 눈길\"                              \n",
       "8363  \"[SC이슈]\"\"마약·백스텝·김새롬 탓\"\" '실형 피한' 이찬오, 이미지는 치명상(종합)\"             \n",
       "8364  \"[POP이슈]\"\"그들만의 세상\"\"…홍상수♥김민희, 새해데이트에 '반응싸늘'\"                    \n",
       "8365  [종합] '시크릿 마더' 김소연 누가 죽였나…송윤아와 갈등                               \n",
       "8366  \"허지웅·소속사 \"\"악성림프종 진단, 치료 전념\"\" (공식)\"                             \n",
       "\n",
       "                                                                            comment  \\\n",
       "0     김태리 정말 연기 잘해 진짜                                                                 \n",
       "1     공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까                                                  \n",
       "2     누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~          \n",
       "3     일본 축구 져라                                                                        \n",
       "4     난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@                                                    \n",
       "...                            ...                                                    \n",
       "8362  아니 근데. 튜닝한 사람은 프러포즈 받지도. 결혼도 못함? ᄏᄏᄏ 자기들은 돈 없어서 못하는 것들이 ᄏᄏᄏᄏ아이고 배 아파죽지ᄏ         \n",
       "8363  그러니깐 여자를 잘 만나야 돼~징글징글한 것들 만나면 인생 끝가지 돌아가게 되는 듯.. 근데 왜 다들 김새롬 편을 들어.,,? 미친 것들이   \n",
       "8364  참으로 아름다운 커플입니다. 늘 행복하시고 새해에도 늘 꽃길만 걸으시길 축원합니다 ^^ ♡♡♡                            \n",
       "8365  재미가 없어요                                                                         \n",
       "8366  쭉 쉬세요                                                                           \n",
       "\n",
       "        bias  hate  \n",
       "0     none    none  \n",
       "1     none    hate  \n",
       "2     others  hate  \n",
       "3     none    none  \n",
       "4     none    none  \n",
       "...    ...     ...  \n",
       "8362  others  hate  \n",
       "8363  gender  hate  \n",
       "8364  none    none  \n",
       "8365  none    none  \n",
       "8366  none    hate  \n",
       "\n",
       "[8367 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1f3bb60f-18ca-49b3-885d-527ad965b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거\n",
    "# test_df[\"title\"] = test_df[\"title\"].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)\n",
    "# test_df[\"comment\"] = test_df[\"comment\"].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c3c33de-9e5e-4cea-8253-4f34c87f174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['comment'] = test_df['comment'].replace('&', '')\n",
    "# test_df['title'] = test_df['title'].replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccc0009d-98db-4600-bce7-1cfa7ddba634",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['comment'] = test_df['comment'].str.strip('\"')\n",
    "# test_df['title'] = test_df['title'].str.strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "909be505-613e-44e7-9e5f-ba0631f64b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[test_df['title'].str.contains('&')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4436baf3-6953-4810-b9cb-b1a9c4ad1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df[test_df['comment'].str.contains('&')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ca799b5-ee95-43f9-bee8-5a7c6c121fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7058/2478355602.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df['comment'][i] = checked_comment\n"
     ]
    }
   ],
   "source": [
    "# 맞춤법, 띄어쓰기 수정\n",
    "for i in range(len(test_df)):    \n",
    "    # input_title = test_df['title'][i]\n",
    "    input_comment = test_df['comment'][i]\n",
    "\n",
    "    # spelled_title = spell_checker.check(input_title)\n",
    "    spelled_comment = spell_checker.check(input_comment)                       \n",
    "    \n",
    "    # checked_title = spelled_title.checked\n",
    "    checked_comment = spelled_comment.checked\n",
    "    \n",
    "    \n",
    "    # print(spelled_sent.only_checked())\n",
    "    # test_df['title'][i] = checked_title \n",
    "    test_df['comment'][i] = checked_comment     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c279173a-3711-4cf4-a910-dd18ba51eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test_df)):\n",
    "#     test_df['title'][i] = repeat_normalize(test_df['title'][i],  num_repeats=2)\n",
    "#     test_df['comment'][i] = repeat_normalize(test_df['comment'][i],  num_repeats=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b13b60fb-099f-4a5b-8aa4-e6052053edee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]</td>\n",
       "      <td>둘 다 너무 좋다~행복하세요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]</td>\n",
       "      <td>근데 만 원 이하는 현금결제만 하라고 써놓은 집 우리나라에 엄청 많은데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]</td>\n",
       "      <td>누군데 얘네?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"</td>\n",
       "      <td>쇼 하지 마라 자식아! 음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다. 슬금슬금 기어 나올 생각 말고 하던 대로 그냥 조용히 살아라! 잠재적 살인마.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]</td>\n",
       "      <td>안검하수 가지고 있는 분께 희망을 주고 싶은 건가요? 수술하면 이렇게 자연스러워진다고??눈 감았다가 뜨는 동영상 올려보시죠... 정작 안검하수 있는 분들은 수술해도 부작용 때문에.. 눈꺼풀 잘 못 감거든요..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>[N이슈] 최율, 조재현 성추행 의혹 폭로… 소속사 \"상황 파악 중\"</td>\n",
       "      <td>얜 그냥 봐도 아니다 ㅋ 고소당하면 어마어마한 금액 물어줘야 할걸?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"날씨가 좋아서\" [SC컷]</td>\n",
       "      <td>대박 게스트... 꼭 봐야지~ 콘셉트가 바뀌니깐 재미 지네</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>[SS인터뷰①]박민영 \"'김비서' 행복했다..열애설엔 당당..미소였으니까\"</td>\n",
       "      <td>성형으로 다 뜯어고쳐놓고 예쁜 척. 성형 전 네 얼굴 다 알고 있다. 순자처럼 된장 냄새나게 생겼더니만</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>[POP이슈]\"사실무근\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '핫'(종합)</td>\n",
       "      <td>분위기는 비슷하다만 전혀 다른 전개던데 무슨ㅋㅋㄱ 우리나라 사람들은 분위기만 비슷하면 다 표절이래 그럼 클래식 계열도 다 표절이고 재즈 계열도 다 표절이게?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'</td>\n",
       "      <td>입에 손가락이 10개 있으니 징그럽다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0    0    류현경♥︎박성훈, 공개연애 4년차 애정전선 이상無..\"의지 많이 된다\"[종합]         \n",
       "1    1    \"현금 유도+1인 1라면?\"…'골목식당' 백종원, 초심 잃은 도시락집에 '경악' [종합]   \n",
       "2    2    입대 D-11' 서은광의 슬픈 멜로디..비투비, 눈물의 첫 체조경기장[콘서트 종합]      \n",
       "3    3    아이콘택트' 리쌍 길, 3년 전 결혼설 부인한 이유 공개…\"결혼,출산 숨겼다\"         \n",
       "4    4    구하라, 안검하수 반박 해프닝...\"당당하다\"vs\"그렇게까지\" 설전 [종합]          \n",
       "..  ..                                           ...          \n",
       "506  506  [N이슈] 최율, 조재현 성추행 의혹 폭로… 소속사 \"상황 파악 중\"              \n",
       "507  507  해투4' 이서진, 한지민 '대본 리딩 격리설' 해명…\"날씨가 좋아서\" [SC컷]        \n",
       "508  508  [SS인터뷰①]박민영 \"'김비서' 행복했다..열애설엔 당당..미소였으니까\"           \n",
       "509  509  [POP이슈]\"사실무근\" 'SKY캐슬' 측 '위올라이' 표절설 부인→여전히 '핫'(종합)   \n",
       "510  510  오창석♥' 이채은, 웨딩사진?...순백의 드레스 입고 '활짝'                  \n",
       "\n",
       "                                                                                                                  comment  \n",
       "0    둘 다 너무 좋다~행복하세요                                                                                                       \n",
       "1    근데 만 원 이하는 현금결제만 하라고 써놓은 집 우리나라에 엄청 많은데                                                                               \n",
       "2    누군데 얘네?                                                                                                               \n",
       "3    쇼 하지 마라 자식아! 음주 1번은 실수, 2번은 고의, 3번은 인간쓰레기다. 슬금슬금 기어 나올 생각 말고 하던 대로 그냥 조용히 살아라! 잠재적 살인마.                               \n",
       "4    안검하수 가지고 있는 분께 희망을 주고 싶은 건가요? 수술하면 이렇게 자연스러워진다고??눈 감았다가 뜨는 동영상 올려보시죠... 정작 안검하수 있는 분들은 수술해도 부작용 때문에.. 눈꺼풀 잘 못 감거든요..  \n",
       "..                                                                                                                    ...  \n",
       "506  얜 그냥 봐도 아니다 ㅋ 고소당하면 어마어마한 금액 물어줘야 할걸?                                                                                 \n",
       "507  대박 게스트... 꼭 봐야지~ 콘셉트가 바뀌니깐 재미 지네                                                                                      \n",
       "508  성형으로 다 뜯어고쳐놓고 예쁜 척. 성형 전 네 얼굴 다 알고 있다. 순자처럼 된장 냄새나게 생겼더니만                                                             \n",
       "509  분위기는 비슷하다만 전혀 다른 전개던데 무슨ㅋㅋㄱ 우리나라 사람들은 분위기만 비슷하면 다 표절이래 그럼 클래식 계열도 다 표절이고 재즈 계열도 다 표절이게?                               \n",
       "510  입에 손가락이 10개 있으니 징그럽다                                                                                                  \n",
       "\n",
       "[511 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0cfd9-1787-4a9b-b7e2-44552a87dac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "38c61bc4-da4a-4fc3-9cff-62079051ed82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['none' 'none']\n",
      " ['none' 'hate']\n",
      " ['others' 'none']\n",
      " ['others' 'hate']\n",
      " ['gender' 'none']\n",
      " ['gender' 'hate']]\n"
     ]
    }
   ],
   "source": [
    "# 두 라벨의 가능한 모든 조합 만들기\n",
    "combinations = np.array(np.meshgrid(train_df.bias.unique(), train_df.hate.unique())).T.reshape(-1,2)\n",
    "\n",
    "if DEBUG==True:\n",
    "    print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c1f00cb-8009-460f-8903-ca876d647ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['none', 'none'], dtype=object), array(['none', 'hate'], dtype=object), array(['others', 'hate'], dtype=object), array(['none', 'none'], dtype=object), array(['none', 'none'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "# bias, hate 컬럼을 합친 것\n",
    "bias_hate = list(np.array([train_df['bias'].values, train_df['hate'].values]).T.reshape(-1,2))\n",
    "\n",
    "if DEBUG==True:\n",
    "    print(bias_hate[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26376de0-2a54-44c2-a8af-f20025b9798b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"</td>\n",
       "      <td>김태리 정말 연기 잘해 진짜</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"</td>\n",
       "      <td>공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"</td>\n",
       "      <td>누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"</td>\n",
       "      <td>일본 축구 져라</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"</td>\n",
       "      <td>난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          title  \\\n",
       "0  \"'미스터 션샤인' 변요한, 김태리와 같은 양복 입고 학당 방문! 이유는?\"                     \n",
       "1  \"[SC현장]\"\"극사실주의 현실♥\"\"…'가장 보통의 연애' 김래원X공효진, 16년만의 랑데부(종합)\"       \n",
       "2  \"손연재, 리듬체조 학원 선생님 \"\"하고 싶은 일 해서 행복하다\"\"\"                         \n",
       "3  \"'섹션TV' 김해숙 \"\"'허스토리' 촬영 후 우울증 얻었다\"\"\"                           \n",
       "4  \"[단독] 임현주 아나운서 “‘노브라 챌린지’ 방송 덕에 낸 용기, 자연스런 논의의 창 됐으면” (인터뷰)\"   \n",
       "\n",
       "                                                                  comment  \\\n",
       "0  김태리 정말 연기 잘해 진짜                                                          \n",
       "1  공효진 발 연기나 이질 생각이 없던데 왜 계속 주연일까                                           \n",
       "2  누구처럼 돈만 밝히는 저급 인생은 살아가지 마시길~~ 행복은 머니 순이 아니니깐 작은 거에 감사하고 항상 좋은 일만 가득하길~   \n",
       "3  일본 축구 져라                                                                 \n",
       "4  난 절대로 임현주 욕하는 인간이랑은 안 논다 @.@                                             \n",
       "\n",
       "     bias  hate  label  \n",
       "0  none    none  0      \n",
       "1  none    hate  1      \n",
       "2  others  hate  3      \n",
       "3  none    none  0      \n",
       "4  none    none  0      "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "for i, arr in enumerate(bias_hate):\n",
    "    for idx, elem in enumerate(combinations):\n",
    "        if np.array_equal(elem, arr):\n",
    "            labels.append(idx)\n",
    "\n",
    "train_df['label'] = labels\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add80824-55c5-4ca3-9858-5aeee3ede98d",
   "metadata": {},
   "source": [
    "## 3. Dataset 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9956c57-af6a-4330-a531-a338be9da9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3-0. Pre-trained tokenizer 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd6f75f4-cdf7-4998-8b78-3aa716b7045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.json 에서 지정 이름별로 가져올 라이브러리 지정\n",
    "\n",
    "TOKENIZER_CLASSES = {\n",
    "    \"BertTokenizer\": BertTokenizer,\n",
    "    \"AutoTokenizer\": AutoTokenizer,\n",
    "    \"ElectraTokenizer\": ElectraTokenizer,\n",
    "    \"AlbertTokenizer\": AlbertTokenizer\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a285fec-0b39-4dce-8dc0-6faa6b027c34",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Tokenizer 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d0f1e57-caf8-4d67-a2a9-61284a793f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'ElectraTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreTrainedTokenizer(name_or_path='beomi/KcELECTRA-base', vocab_size=50135, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = TOKENIZER_CLASSES[args.tokenizer_class].from_pretrained(args.pretrained_model)\n",
    "if DEBUG==True:\n",
    "    print(TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e8cdb8e-41a8-4d51-8aa0-f305782416ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 6, 11, 24787, 2089, 5146, 4028, 11, 1709, 4071, 4069, 16, 20778, 4177, 4331, 8069, 35054, 12634, 47185, 13182, 5, 10491, 33, 6, 3, 20778, 4177, 8057, 11061, 12751, 7997, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "if DEBUG == True:\n",
    "    example = train_df['title'][0]\n",
    "    comment_ex = train_df['comment'][0]\n",
    "    print(TOKENIZER(example, comment_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f174365c-90da-4c32-b6b4-5d66525a0687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6, 11, 24787, 2089, 5146, 4028, 11, 1709, 4071, 4069, 16, 20778, 4177, 4331, 8069, 35054, 12634, 47185, 13182, 5, 10491, 33, 6, 3] \n",
      "\n",
      "['\"', \"'\", '미스터', '션', '##샤', '##인', \"'\", '변', '##요', '##한', ',', '김태', '##리', '##와', '같은', '양복', '입고', '학당', '방문', '!', '이유는', '?', '\"'] \n",
      "\n",
      "[6, 11, 24787, 2089, 5146, 4028, 11, 1709, 4071, 4069, 16, 20778, 4177, 4331, 8069, 35054, 12634, 47185, 13182, 5, 10491, 33, 6]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG==True:\n",
    "    print(TOKENIZER.encode(example),\"\\n\")\n",
    "    \n",
    "    # 토큰으로 나누기\n",
    "    print(TOKENIZER.tokenize(example),\"\\n\")\n",
    "    \n",
    "    # 토큰 id로 매핑하기\n",
    "    print(TOKENIZER.convert_tokens_to_ids(TOKENIZER.tokenize(example)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb0d69-e6c3-447c-97ea-08fcce6767fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cbf1708e-aedb-402f-a9c3-20ebdbe537eb",
   "metadata": {},
   "source": [
    "### 3-1. Dataset 만드는 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "85e6f065-671c-435c-8e73-8cad3c1496a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, tokenizer, max_len, mode = 'train'):\n",
    "\n",
    "        self.data = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.mode = mode\n",
    "        \n",
    "        if self.mode!='test':\n",
    "            try: \n",
    "                self.labels = df['label'].tolist()\n",
    "            except:\n",
    "                assert False, 'CustomDataset Error : \\'label\\' column does not exist in the dataframe'\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "                \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        전체 데이터에서 특정 인덱스 (idx)에 해당하는 기사제목과 댓글 내용을 \n",
    "        토크나이즈한 data('input_ids', 'attention_mask','token_type_ids')의 딕셔너리 형태로 불러옴\n",
    "        \"\"\"\n",
    "        # title = self.data.title.iloc[idx]\n",
    "        comment = self.data.comment.iloc[idx]\n",
    "        \n",
    "        tokenized_text = self.tokenizer( comment,\n",
    "                             padding= 'max_length',\n",
    "                             max_length=self.max_len,\n",
    "                             truncation=True,\n",
    "                             return_token_type_ids=True,\n",
    "                             return_attention_mask=True,\n",
    "                             return_tensors = \"pt\")\n",
    "        \n",
    "        data = {'input_ids': tokenized_text['input_ids'].clone().detach().long(),\n",
    "               'attention_mask': tokenized_text['attention_mask'].clone().detach().long(),\n",
    "               'token_type_ids': tokenized_text['token_type_ids'].clone().detach().long(),\n",
    "               }\n",
    "        \n",
    "        if self.mode != 'test':\n",
    "            label = self.data.label.iloc[idx]\n",
    "            return data, label\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "\n",
    "    \n",
    "train_dataset = CustomDataset(train_df, TOKENIZER, args.max_seq_len, mode ='train')\n",
    "print(\"train dataset loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7d27241c-4c3b-498e-9456-871dc3cc2e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset sample : \n",
      "({'input_ids': tensor([[    2, 20778,  4177,  8057, 11061, 12751,  7997,     3,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}, 0)\n"
     ]
    }
   ],
   "source": [
    "if DEBUG ==True :\n",
    "    print(\"dataset sample : \")\n",
    "    print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbadd376-0df2-455c-89f1-9236ba9d32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_plus = tokenizer.encode_plus(\n",
    "#                     sentence,                      # Sentence to encode.\n",
    "#                     add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#                     max_length = 128,           # Pad & truncate all sentences.\n",
    "#                     pad_to_max_length = True,\n",
    "#                     return_attention_mask = True,   # Construct attention masks.\n",
    "#                     return_tensors = 'pt',     # Return pytorch tensors.\n",
    "#                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92d12dd-7a1e-423f-8b3d-00bae3c17375",
   "metadata": {},
   "source": [
    "### 3-2. Train, Validation set 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6fb9525-861d-48ba-b495-828b8a08b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:  7530\n",
      "Validation dataset:  837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "                                                         \n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=args.seed)\n",
    "\n",
    "train_dataset = CustomDataset(train_data, TOKENIZER, args.max_seq_len, 'train')\n",
    "val_dataset = CustomDataset(val_data, TOKENIZER, args.max_seq_len, 'validation')\n",
    "\n",
    "print(\"Train dataset: \", len(train_dataset))\n",
    "print(\"Validation dataset: \", len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed493727-edd8-43ba-924f-195837306952",
   "metadata": {},
   "source": [
    "## 4. 분류 모델 학습을 위한 세팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c0817a-8b51-4d22-9f31-eb8bd22640cb",
   "metadata": {},
   "source": [
    "### 4-1. 아키텍쳐 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a250764-25aa-43e4-a383-f464dc54bc25",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "- [PretrainedConfig](https://huggingface.co/docs/transformers/v4.16.2/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained)\n",
    "-[KcELECTRA 사전학습 모델](https://github.com/Beomi/KcELECTRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "554c0acd-d158-4d36-bfd1-abb47fb618f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElectraForSequenceClassification(\n",
      "  (electra): ElectraModel(\n",
      "    (embeddings): ElectraEmbeddings(\n",
      "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): ElectraEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): ElectraLayer(\n",
      "          (attention): ElectraAttention(\n",
      "            (self): ElectraSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): ElectraSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ElectraIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): ElectraOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): ElectraClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# config.json 에 입력된 architecture 에 따라 베이스 모델 설정\n",
    "BASE_MODELS = {\n",
    "    \"BertForSequenceClassification\": BertForSequenceClassification,\n",
    "    \"AutoModel\": AutoModel,\n",
    "    \"ElectraForSequenceClassification\": ElectraForSequenceClassification,\n",
    "    \"AlbertForSequenceClassification\": AlbertForSequenceClassification,\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "myModel = BASE_MODELS[args.architecture].from_pretrained(args.pretrained_model, \n",
    "                                                         num_labels = args.num_classes, \n",
    "                                                         output_attentions = False, # Whether the model returns attentions weights.\n",
    "                                                         output_hidden_states = True # Whether the model returns all hidden-states.\n",
    "                                                        )\n",
    "if DEBUG==True:\n",
    "    # 모델 구조 확인\n",
    "    print(myModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5f90f3c-51f6-4b44-a426-a0b36ccfa852",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c022a093-130f-40ac-b8e5-8decc5c63a6d",
   "metadata": {},
   "source": [
    "### 4-2. 모델 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d37b1b-d491-4d3c-8551-980f78a78337",
   "metadata": {},
   "source": [
    "\n",
    "- BertForSequenceClassifier (line 1232부터 참고) [source code](https://github.com/huggingface/transformers/blob/a39dfe4fb122c11be98a563fb8ca43b322e01036/src/transformers/modeling_bert.py#L1284-L1287)\n",
    "\n",
    "- ElectraForSequenceClassifier [source code](https://huggingface.co/transformers/v3.0.2/_modules/transformers/modeling_electra.html#ElectraForSequenceClassification)\n",
    "\n",
    "- SequenceClassier output 형태 : tuple(torch.FloatTensor)\n",
    "    - loss (torch.FloatTensor of shape (1,), optional, returned when label is provided):\n",
    "    Classification (or regression if config.num_labels==1) loss.\n",
    "\n",
    "   - logits (torch.FloatTensor of shape (batch_size, config.num_labels)):\n",
    "    Classification (or regression if config.num_labels==1) scores (before SoftMax).\n",
    "\n",
    "    - hidden_states (tuple(torch.FloatTensor), optional, returned when output_hidden_states=True is passed or when config.output_hidden_states=True):\n",
    "    Tuple of torch.FloatTensor (one for the output of the embeddings + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
    "\n",
    "    - Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "\n",
    "    - attentions (tuple(torch.FloatTensor), optional, returned when output_attentions=True is passed or when config.output_attentions=True):\n",
    "Tuple of torch.FloatTensor (one for each layer) of shape (batch_size, num_heads, sequence_length, sequence_length).\n",
    "\n",
    "    Attentions weights after the attention softmax, used to compute the weighted average in the self-attention heads.\n",
    "    \n",
    "    \n",
    "- v2 에서 수정 및 추가 된 부분 많음\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1685ce12-7238-4e2a-a20d-11969b568807",
   "metadata": {},
   "outputs": [],
   "source": [
    "### v2 에서 일부 수정됨\n",
    "class myClassifier(nn.Module):\n",
    "    def __init__(self, model, hidden_size = 768, num_classes=args.num_classes, selected_layers=False, params=None):\n",
    "        super(myClassifier, self).__init__()\n",
    "        self.model = model\n",
    "        self.softmax = nn.Softmax(dim=1) \n",
    "        self.selected_layers = selected_layers\n",
    "        \n",
    "        # 사실 dr rate은 model config 에서 hidden_dropout_prob로 가져와야 하는데 bert에선 0.1이 쓰였음\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "\n",
    "    def forward(self, token_ids, attention_mask, segment_ids):      \n",
    "        outputs = self.model(input_ids = token_ids, \n",
    "                             token_type_ids = segment_ids.long(), \n",
    "                             attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        \n",
    "        # hidden state에서 마지막 4개 레이어를 뽑아 합쳐 새로운 pooled output 을 만드는 시도\n",
    "        if self.selected_layers == True:\n",
    "            hidden_states = outputs.hidden_states\n",
    "            pooled_output = torch.cat(tuple([hidden_states[i] for i in [-4, -3, -2, -1]]), dim=-1)\n",
    "            # print(\"concatenated output shape: \", pooled_output.shape)\n",
    "            ## dim(batch_size, max_seq_len, hidden_dim) 에서 가운데를 0이라 지정함으로, [cls] 토큰의 임베딩을 가져온다. \n",
    "            ## (text classification 구조 참고)\n",
    "            pooled_output = pooled_output[:, 0, :]\n",
    "            # print(pooled_output)\n",
    "\n",
    "            pooled_output = self.dropout(pooled_output)\n",
    "\n",
    "            ## 3개의 레이어를 합치므로 classifier의 차원은 (hidden_dim, 6)이다\n",
    "            classifier = nn.Linear(pooled_output.shape[1], args.num_classes).to(token_ids.device)\n",
    "            logits = classifier(pooled_output)\n",
    "        \n",
    "        else:\n",
    "            logits=outputs.logits\n",
    "        \n",
    "    \n",
    "        # 각 클래스별 확률\n",
    "        prob= self.softmax(logits)\n",
    "        # print(prob)\n",
    "        # logits2 = outputs.logits\n",
    "        # print(self.softmax(logits2))\n",
    "\n",
    "\n",
    "        return logits, prob\n",
    "        \n",
    "# 마지막 4 hidden layers concat 하는 방법을 쓰신다면 True로 변경        \n",
    "model = myClassifier(myModel, selected_layers=False)\n",
    "\n",
    "# if DEBUG ==True :\n",
    "#     print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf359650-bc3c-4a9d-b486-e25496932285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99386a8c-7795-454c-9a32-eaf447c6fc4c",
   "metadata": {},
   "source": [
    "### 4-3. 모델 구성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e3b6bc6f-1df3-46fb-a607-5de3e3cef571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "model.electra.embeddings.word_embeddings.weight         (50135, 768)\n",
      "model.electra.embeddings.position_embeddings.weight       (512, 768)\n",
      "model.electra.embeddings.token_type_embeddings.weight       (2, 768)\n",
      "model.electra.embeddings.LayerNorm.weight                     (768,)\n",
      "model.electra.embeddings.LayerNorm.bias                       (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "model.electra.encoder.layer.0.attention.self.query.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.query.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.self.key.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.key.bias         (768,)\n",
      "model.electra.encoder.layer.0.attention.self.value.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.self.value.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.dense.weight   (768, 768)\n",
      "model.electra.encoder.layer.0.attention.output.dense.bias       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "model.electra.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "model.electra.encoder.layer.0.intermediate.dense.weight  (3072, 768)\n",
      "model.electra.encoder.layer.0.intermediate.dense.bias        (3072,)\n",
      "model.electra.encoder.layer.0.output.dense.weight        (768, 3072)\n",
      "model.electra.encoder.layer.0.output.dense.bias               (768,)\n",
      "model.electra.encoder.layer.0.output.LayerNorm.weight         (768,)\n",
      "model.electra.encoder.layer.0.output.LayerNorm.bias           (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "model.classifier.dense.weight                             (768, 768)\n",
      "model.classifier.dense.bias                                   (768,)\n",
      "model.classifier.out_proj.weight                            (6, 768)\n",
      "model.classifier.out_proj.bias                                  (6,)\n"
     ]
    }
   ],
   "source": [
    "if DEBUG==True:\n",
    "    params = list(model.named_parameters())\n",
    "\n",
    "    print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "    print('==== Embedding Layer ====\\n')\n",
    "\n",
    "    for p in params[0:5]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "    for p in params[5:21]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "    print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "    for p in params[-4:]:\n",
    "        print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c441a1-2ce3-46b2-b52d-c0cce7f76873",
   "metadata": {},
   "source": [
    "## 5. 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4643714-c372-463a-8f7e-2955b2d4376a",
   "metadata": {},
   "source": [
    "### 5-0. Early Stopper 함수 정의\n",
    "\n",
    "- v2에서 코드 일부 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c205350d-ce58-42e7-9558-2b405f142ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossEarlyStopper():\n",
    "    \"\"\"Early stopper\n",
    "\n",
    "        patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "        patience_counter (int): loss 가 줄어들지 않을 때 마다 1씩 증가\n",
    "        min_loss (float): 최소 loss\n",
    "        stop (bool): True 일 때 학습 중단\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int)-> None:\n",
    "        \"\"\" 초기화\n",
    "\n",
    "        Args:\n",
    "            patience (int): loss가 줄어들지 않아도 학습할 epoch 수\n",
    "            weight_path (str): weight 저장경로\n",
    "            verbose (bool): 로그 출력 여부, True 일 때 로그 출력\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.patience_counter = 0\n",
    "        self.min_loss = np.Inf\n",
    "        self.stop = False\n",
    "\n",
    "    def check_early_stopping(self, loss: float)-> None:\n",
    "        # 첫 에폭\n",
    "        if self.min_loss == np.Inf:\n",
    "            self.min_loss = loss\n",
    "           \n",
    "        # loss가 줄지 않는다면 -> patience_counter 1 증가\n",
    "        elif loss > self.min_loss:\n",
    "            self.patience_counter += 1\n",
    "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
    "\n",
    "            # patience 만큼 loss가 줄지 않았다면 학습을 중단합니다.\n",
    "            if self.patience_counter == self.patience:\n",
    "                self.stop = True\n",
    "            print(msg)\n",
    "        # loss가 줄어듬 -> min_loss 갱신, patience_counter 초기화\n",
    "        elif loss <= self.min_loss:\n",
    "            self.patience_counter = 0\n",
    "            ### v2 에서 수정됨\n",
    "            ### self.save_model = True -> 삭제 (사용하지 않음)\n",
    "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
    "            self.min_loss = loss\n",
    "\n",
    "            print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d11163-6def-448a-9095-19231e9efe64",
   "metadata": {},
   "source": [
    "### 5-1. Epoch 별 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ed2a1-c2e3-43cb-9967-05d85b8546ee",
   "metadata": {},
   "source": [
    "- [Transformers optimization documentation](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules)\n",
    "- [스케줄러 documentation](https://huggingface.co/docs/transformers/main_classes/optimizer_schedules#schedules)\n",
    "- Adam optimizer의 epsilon 파라미터 eps = 1e-8 는 \"계산 중 0으로 나눔을 방지 하기 위한 아주 작은 숫자 \" 입니다. ([출처](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/))\n",
    "- 스케줄러 파라미터\n",
    "    - `warmup_ratio` : \n",
    "      - 학습이 진행되면서 학습률을 그 상황에 맞게 가변적으로 적당하게 변경되게 하기 위해 Scheduler를 사용합니다.\n",
    "      - 처음 학습률(Learning rate)를 warm up하기 위한 비율을 설정하는 warmup_ratio을 설정합니다.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "80dcce99-8986-4ef8-a923-4bbcbf55cb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtkddn2075\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d151484e-978d-4bf3-b7b3-fe2c5ba5eda5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config file loaded.\n",
      "beomi/KcELECTRA-base\n",
      "RUN :  demo1_adamW\n",
      "batch size :  16\n",
      "The first batch looks like ..\n",
      " {'input_ids': tensor([[[    2,  8249,  3508,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2, 33497,  4461,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2,  1173,  4082,  ...,     0,     0,     0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    2,  8904,  8518,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2,  3468,  4261,  ...,     0,     0,     0]],\n",
      "\n",
      "        [[    2,  2741,  4626,  ...,     0,     0,     0]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0]]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.11 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/tkddn2075/NLP%20Augmentation/runs/4ue0hfq5\" target=\"_blank\">Electra learning rate=5e-5, adam=5e-5, inputsize=32</a></strong> to <a href=\"https://wandb.ai/tkddn2075/NLP%20Augmentation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:04<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1                 | Train Loss:  0.079                 | Train Accuracy:  0.501                 | Val Loss:  0.061                 | Val Accuracy:  0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:216: UserWarning: Please also save or load the state of the optimizer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "100% 471/471 [15:18<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2                 | Train Loss:  0.049                 | Train Accuracy:  0.712                 | Val Loss:  0.056                 | Val Accuracy:  0.664\n",
      "Validation loss decreased 0.06077452116115119 -> 0.05555605437949282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:16<00:00,  1.95s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3                 | Train Loss:  0.024                 | Train Accuracy:  0.874                 | Val Loss:  0.067                 | Val Accuracy:  0.655\n",
      "Early stopping counter 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:06<00:00,  1.92s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4                 | Train Loss:  0.010                 | Train Accuracy:  0.951                 | Val Loss:  0.077                 | Val Accuracy:  0.644\n",
      "Early stopping counter 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:14<00:00,  1.94s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5                 | Train Loss:  0.004                 | Train Accuracy:  0.981                 | Val Loss:  0.102                 | Val Accuracy:  0.651\n",
      "Early stopping counter 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:21<00:00,  1.96s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6                 | Train Loss:  0.002                 | Train Accuracy:  0.992                 | Val Loss:  0.113                 | Val Accuracy:  0.639\n",
      "Early stopping counter 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:06<00:00,  1.93s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7                 | Train Loss:  0.001                 | Train Accuracy:  0.998                 | Val Loss:  0.123                 | Val Accuracy:  0.642\n",
      "Early stopping counter 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:16<00:00,  1.95s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8                 | Train Loss:  0.000                 | Train Accuracy:  0.999                 | Val Loss:  0.130                 | Val Accuracy:  0.626\n",
      "Early stopping counter 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:23<00:00,  1.96s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9                 | Train Loss:  0.000                 | Train Accuracy:  0.999                 | Val Loss:  0.142                 | Val Accuracy:  0.646\n",
      "Early stopping counter 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:24<00:00,  1.96s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10                 | Train Loss:  0.000                 | Train Accuracy:  1.000                 | Val Loss:  0.144                 | Val Accuracy:  0.648\n",
      "Early stopping counter 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:19<00:00,  1.95s/it]\n",
      "  0% 0/471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11                 | Train Loss:  0.000                 | Train Accuracy:  1.000                 | Val Loss:  0.146                 | Val Accuracy:  0.648\n",
      "Early stopping counter 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 471/471 [15:23<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12                 | Train Loss:  0.000                 | Train Accuracy:  1.000                 | Val Loss:  0.148                 | Val Accuracy:  0.649\n",
      "Early stopping counter 10/10\n",
      "Early stopped, Best score :  0.6642771804062126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 7193... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▆▇████████</td></tr><tr><td>train_loss</td><td>█▅▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃█▆▄▆▃▄▁▅▅▅▅</td></tr><tr><td>val_loss</td><td>▁▁▂▃▄▅▆▇████</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>1.0</td></tr><tr><td>train_loss</td><td>3e-05</td></tr><tr><td>val_accuracy</td><td>0.64875</td></tr><tr><td>val_loss</td><td>0.14817</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">Electra learning rate=5e-5, adam=5e-5, inputsize=32</strong>: <a href=\"https://wandb.ai/tkddn2075/NLP%20Augmentation/runs/4ue0hfq5\" target=\"_blank\">https://wandb.ai/tkddn2075/NLP%20Augmentation/runs/4ue0hfq5</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220303_175230-4ue0hfq5/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train finished\n"
     ]
    }
   ],
   "source": [
    "args = set_config(config_path)\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "\n",
    "# 재현을 위해 모든 곳의 시드 고정\n",
    "seed_val = args.seed\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "def train(model, train_data, val_data, args, mode = 'train'):\n",
    "    \n",
    "    # args.run은 실험 이름 (어디까지나 팀원들간의 버전 관리 및 공유 편의를 위한 것으로, 자유롭게 수정 가능합니다.)\n",
    "    print(\"RUN : \", args.run)\n",
    "    shutil.copyfile(\"config.json\", os.path.join(args.config_dir, f\"config_{args.run}.json\"))\n",
    "\n",
    "    early_stopper = LossEarlyStopper(patience=args.patience)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=args.train_batch_size, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_data, batch_size=args.train_batch_size)\n",
    "\n",
    "    \n",
    "    if DEBUG == True:\n",
    "        # 데이터로더가 성공적으로 로드 되었는지 확인\n",
    "        for idx, data in enumerate(train_dataloader):\n",
    "            if idx==0:\n",
    "                print(\"batch size : \", len(data[0]['input_ids']))\n",
    "                print(\"The first batch looks like ..\\n\", data[0])\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    total_steps = len(train_dataloader) * args.train_epochs\n",
    "\n",
    "    ### v2에서 수정됨 (Adam -> AdamW)\n",
    "    optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * args.warmup_proportion), \n",
    "                                                num_training_steps=total_steps)\n",
    "\n",
    "    \n",
    "    if use_cuda:\n",
    "        model = model.to(DEVICE)\n",
    "        criterion = criterion.to(DEVICE)\n",
    "        \n",
    "\n",
    "    tr_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "    best_score = 0.0\n",
    "    ### v2에서 변경됨\n",
    "    best_loss = np.inf\n",
    "    wandb.init(project='NLP Augmentation', name='Electra learning rate=5e-5, adam=5e-5, inputsize=32')\n",
    "    wandb.watch(model, log='all', log_freq=10)\n",
    "\n",
    "    for epoch_num in range(args.train_epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "            \n",
    "            assert mode in ['train', 'val'], 'your mode should be either \\'train\\' or \\'val\\''\n",
    "            \n",
    "            if mode =='train':\n",
    "                for train_input, train_label in tqdm(train_dataloader):\n",
    "                    \n",
    "                    \n",
    "                    mask = train_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = train_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = train_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    train_label = train_label.long().to(DEVICE)  \n",
    "                    \n",
    "                    ### v2에 수정됨\n",
    "                    optimizer.zero_grad()\n",
    " \n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "                    batch_loss = criterion(output[0].view(-1,6), train_label.view(-1))\n",
    "                    total_loss_train += batch_loss.item()\n",
    "\n",
    "                    acc = (output[0].argmax(dim=1) == train_label).sum().item()\n",
    "                    total_acc_train += acc\n",
    "                    \n",
    "                    ### v2에 수정됨\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    batch_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    ### v2 에 수정됨\n",
    "                    scheduler.step()\n",
    "                    \n",
    "\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "            \n",
    "            # validation을 위해 이걸 넣으면 이 evaluation 프로세스 중엔 dropout 레이어가 다르가 동작한다.\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    mask = val_input['attention_mask'].to(DEVICE)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "                    segment_ids = val_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "                    val_label = val_label.long().to(DEVICE)\n",
    "\n",
    "                    output = model(input_id, mask, segment_ids)\n",
    "                    ### v2 에서 일부 수정 (output -> output[0]로 myClassifier 모델에 정의된대로 logits 가져옴)\n",
    "                    batch_loss = criterion(output[0].view(-1,6), val_label.view(-1))\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    ### v2 에서 일부 수정 (output -> output[0]로 myClassifier 모델에 정의된대로 logits 가져옴)\n",
    "                    acc = (output[0].argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            \n",
    "            train_loss = total_loss_train / len(train_data)\n",
    "            train_accuracy = total_acc_train / len(train_data)\n",
    "            val_loss = total_loss_val / len(val_data)\n",
    "            val_accuracy = total_acc_val / len(val_data)\n",
    "            \n",
    "            # 한 Epoch 학습 후 학습/검증에 대해 loss와 평가지표 (여기서는 accuracy로 임의로 설정) 출력\n",
    "            print(\n",
    "                f'Epoch: {epoch_num + 1} \\\n",
    "                | Train Loss: {train_loss: .3f} \\\n",
    "                | Train Accuracy: {train_accuracy: .3f} \\\n",
    "                | Val Loss: {val_loss: .3f} \\\n",
    "                | Val Accuracy: {val_accuracy: .3f}')\n",
    "          \n",
    "            # early_stopping check\n",
    "            early_stopper.check_early_stopping(loss=val_loss)\n",
    "            \n",
    "            wandb.log({\"train_loss\": train_loss}, step=epoch_num)\n",
    "            wandb.log({\"train_accuracy\": train_accuracy}, step=epoch_num)\n",
    "            wandb.log({\"val_loss\": val_loss}, step=epoch_num)\n",
    "            wandb.log({\"val_accuracy\": val_accuracy}, step=epoch_num)\n",
    "            if early_stopper.stop:\n",
    "                print('Early stopped, Best score : ', best_score)\n",
    "                break\n",
    "\n",
    "            ### v2 에 수정됨\n",
    "            ### loss와 accuracy가 꼭 correlate하진 않습니다.\n",
    "            ### \n",
    "            ### 원본 (필요하다면 다시 해제 후 사용)\n",
    "            # if val_accuracy > best_score : \n",
    "            if val_loss < best_loss :\n",
    "            # 모델이 개선됨 -> 검증 점수와 베스트 loss, weight 갱신\n",
    "                best_score = val_accuracy \n",
    "                \n",
    "                ### v2에서 추가\n",
    "                best_loss =val_loss\n",
    "                # 학습된 모델을 저장할 디렉토리 및 모델 이름 지정\n",
    "                SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "            \n",
    "                check_point = {\n",
    "                    'model': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'scheduler': scheduler.state_dict()\n",
    "                }\n",
    "                torch.save(check_point, SAVED_MODEL)  \n",
    "              \n",
    "            # print(\"scheduler : \", scheduler.state_dict())\n",
    "    wandb.finish()\n",
    "\n",
    "    print(\"train finished\")\n",
    "\n",
    "\n",
    "train(model, train_dataset, val_dataset, args, mode = 'train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6301514c-7d9e-4f37-9e8c-db85e3819b8b",
   "metadata": {},
   "source": [
    "## 6. Test dataset으로 추론 (Prediction)\n",
    "\n",
    "\n",
    "- v2 에서 수정된 부분\n",
    "    - output -> output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "32696c34-b5e6-43b3-a1e7-ed8c2847baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 테스트 데이터셋 불러오기\n",
    "test_data = CustomDataset(test_df, tokenizer = TOKENIZER, max_len= args.max_seq_len, mode='test')\n",
    "\n",
    "def test(model, SAVED_MODEL, test_data, args, mode = 'test'):\n",
    "\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=args.eval_batch_size)\n",
    "\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.to(DEVICE)\n",
    "        model.load_state_dict(torch.load(SAVED_MODEL)['model'])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_input in test_dataloader:\n",
    "\n",
    "            mask = test_input['attention_mask'].to(DEVICE)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(DEVICE)\n",
    "            segment_ids = test_input['token_type_ids'].squeeze(1).to(DEVICE)\n",
    "\n",
    "            output = model(input_id, mask, segment_ids)\n",
    "\n",
    "            output = output[0].argmax(dim=1).cpu().tolist()\n",
    "\n",
    "            for label in output:\n",
    "                pred.append(label)\n",
    "                \n",
    "    return pred\n",
    "\n",
    "SAVED_MODEL =  os.path.join(args.result_dir, f'best_{args.run}.pt')\n",
    "\n",
    "pred = test(model, SAVED_MODEL, test_data, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29432647-7a5d-4dda-99af-ad6f151fd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction completed for  511 comments\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction completed for \", len(pred), \"comments\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8aaf8d-93c6-4998-b005-f32ec5986f46",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ccc3c34-e3a8-4172-8b16-f1c2a5bb5a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode Completed!\n"
     ]
    }
   ],
   "source": [
    "# 0-5 사이의 라벨 값 별로 bias, hate로 디코딩 하기 위한 딕셔너리\n",
    "bias_dict = {0: 'none', 1: 'none', 2: 'others', 3:'others', 4:'gender', 5:'gender'}\n",
    "hate_dict = {0: 'none', 1: 'hate', 2: 'none', 3:'hate', 4:'none', 5:'hate'}\n",
    "\n",
    "# 인코딩 값으로 나온 타겟 변수를 디코딩\n",
    "pred_bias = ['' for i in range(len(pred))]\n",
    "pred_hate = ['' for i in range(len(pred))]\n",
    "\n",
    "for idx, label in enumerate(pred):\n",
    "    pred_bias[idx]=(str(bias_dict[label]))\n",
    "    pred_hate[idx]=(str(hate_dict[label]))\n",
    "print('decode Completed!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75e6cdb3-8245-468e-aaf0-4e6f328e98c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  bias  hate\n",
       "0    0    none  none\n",
       "1    1    none  none\n",
       "2    2    none  none\n",
       "3    3    none  none\n",
       "4    4    none  none\n",
       "..  ..     ...   ...\n",
       "506  506  none  none\n",
       "507  507  none  none\n",
       "508  508  none  none\n",
       "509  509  none  none\n",
       "510  510  none  none\n",
       "\n",
       "[511 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv(os.path.join(args.data_dir,'sample_submission.csv'))\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9265e1ac-0b0b-46eb-a892-307545f8fb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>bias</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>506</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>507</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>508</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>509</td>\n",
       "      <td>others</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>510</td>\n",
       "      <td>none</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID    bias  hate\n",
       "0    0    none    none\n",
       "1    1    none    none\n",
       "2    2    none    hate\n",
       "3    3    none    hate\n",
       "4    4    none    hate\n",
       "..  ..     ...     ...\n",
       "506  506  none    hate\n",
       "507  507  none    none\n",
       "508  508  others  hate\n",
       "509  509  others  hate\n",
       "510  510  none    hate\n",
       "\n",
       "[511 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit['bias'] = pred_bias\n",
    "submit['hate'] = pred_hate\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "964b5159-8ffe-4cc2-833b-3c4b0c857022",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(args.result_dir, f\"submission_{args.run}.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a30767-7803-448a-950b-412b71088d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89023af-867b-4d28-b30d-e465d0abe66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5195d-ddb2-498e-a460-aaf03870df25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
